[{"path":"index.html","id":"machine-learning","chapter":"IMAP-Part 10: Predictive Modeling Using Microbiome Data","heading":"IMAP-Part 10: Predictive Modeling Using Microbiome Data","text":"","code":""},{"path":"index.html","id":"welcome-to-imap-chapter-10-machine-learning-guide-for-microbiome-data","chapter":"IMAP-Part 10: Predictive Modeling Using Microbiome Data","heading":"Welcome to IMAP chapter 10: Machine Learning Guide for Microbiome Data","text":"Welcome exploration machine learning’s pivotal role deciphering microbiome data. realm biomedical research, understanding microbial communities interactions host organisms crucial unraveling complexities health disease.Machine learning techniques offer powerful tools analyze vast amounts genetic, metagenomic, metadata generated microbiome studies. leveraging computational algorithms, researchers can extract meaningful patterns, predict microbial behavior, uncover associations various health conditions.Throughout guide, ’ll delve application machine learning microbiome research, exploring computational techniques revolutionizing understanding microbial ecosystems. Together, ’ll uncover insights intricate relationships microbial communities implications human health environmental sustainability.Join us journey navigate fascinating intersection machine learning microbiome research, discover transformative potential computational techniques advancing biomedical science.","code":""},{"path":"key-components-of-microbiome-machine-learning.html","id":"key-components-of-microbiome-machine-learning","chapter":"1 Key Components of Microbiome Machine Learning","heading":"1 Key Components of Microbiome Machine Learning","text":"Machine learning microbiome research encompasses several key components, playing vital role extracting insights complex microbial data:Feature Engineering: core microbiome analysis lies extraction relevant features diverse data sources, including microbial abundance, diversity metrics, host metadata. Effective feature engineering lays groundwork subsequent analysis model development.Feature Engineering: core microbiome analysis lies extraction relevant features diverse data sources, including microbial abundance, diversity metrics, host metadata. Effective feature engineering lays groundwork subsequent analysis model development.Classification Prediction: Machine learning models play crucial role classifying samples distinct groups (e.g., healthy vs. diseased) predicting clinical outcomes based microbiome profiles. Algorithms Random Forests Neural Networks enable accurate predictions, aiding disease diagnosis prognosis.Classification Prediction: Machine learning models play crucial role classifying samples distinct groups (e.g., healthy vs. diseased) predicting clinical outcomes based microbiome profiles. Algorithms Random Forests Neural Networks enable accurate predictions, aiding disease diagnosis prognosis.Community Profiling: Unsupervised learning techniques, clustering ordination, unveil microbial community structures similarities. characterizing microbial ecosystems, community profiling enhances understanding microbial diversity ecological dynamics.Community Profiling: Unsupervised learning techniques, clustering ordination, unveil microbial community structures similarities. characterizing microbial ecosystems, community profiling enhances understanding microbial diversity ecological dynamics.Microbial Interaction Networks: Graph-based methods uncover intricate co-occurrence patterns identify keystone species within microbial communities. Understanding microbial interactions provides insights ecosystem stability, resilience, functional diversity.Microbial Interaction Networks: Graph-based methods uncover intricate co-occurrence patterns identify keystone species within microbial communities. Understanding microbial interactions provides insights ecosystem stability, resilience, functional diversity.Ecological Modeling: Machine learning algorithms model microbial ecosystem dynamics, capturing complex interactions microbial taxa environment. Ecological modeling elucidates succession patterns, responses environmental changes, ecosystem-level processes.Ecological Modeling: Machine learning algorithms model microbial ecosystem dynamics, capturing complex interactions microbial taxa environment. Ecological modeling elucidates succession patterns, responses environmental changes, ecosystem-level processes.Biomarker Discovery: Feature selection techniques identify microbial taxa pathways serving biomarkers specific health conditions environmental factors. Biomarker discovery facilitates early disease detection, personalized treatment strategies, environmental monitoring.Biomarker Discovery: Feature selection techniques identify microbial taxa pathways serving biomarkers specific health conditions environmental factors. Biomarker discovery facilitates early disease detection, personalized treatment strategies, environmental monitoring.Personalized Medicine:** Machine learning enables development personalized interventions based individual microbiome profiles. integrating microbiome data clinical information, personalized medicine offers targeted therapies preventive strategies tailored individual’s unique microbial composition.Personalized Medicine:** Machine learning enables development personalized interventions based individual microbiome profiles. integrating microbiome data clinical information, personalized medicine offers targeted therapies preventive strategies tailored individual’s unique microbial composition.Together, key components form foundation microbiome machine learning, driving advancements biomedical research, personalized healthcare, environmental sustainability.","code":""},{"path":"ml-framework_R.html","id":"ml-framework_R","chapter":"2 Machine Learning Framework in R: From Data Acquisition to Model Deployment","heading":"2 Machine Learning Framework in R: From Data Acquisition to Model Deployment","text":"Discover comprehensive framework leveraging machine learning R analyze microbiome data. showcase framework using publicly available data microbiome metagenomics analysis, accessible R packages NCBI. capitalizing resources, demonstrate application advanced analytical techniques. initiative underscores value open-access data also highlights broader implications precision medicine personalized healthcare.","code":""},{"path":"ml-framework_R.html","id":"data-acquisition-from-ncbi","chapter":"2 Machine Learning Framework in R: From Data Acquisition to Model Deployment","heading":"2.1 Data Acquisition from NCBI","text":"Data NCBI project PRJEB13870, titled “Gut microbiota dysbiosis contributes development hypertension” Zhao et al., 2017.Data dietswap dataset microbiome package, offering insights impact dietary interventions gut microbiota composition","code":""},{"path":"ml-framework_R.html","id":"model-development-pipeline","chapter":"2 Machine Learning Framework in R: From Data Acquisition to Model Deployment","heading":"2.2 Model Development Pipeline","text":"","code":""},{"path":"ml-framework_R.html","id":"data-cleaning-and-tidying","chapter":"2 Machine Learning Framework in R: From Data Acquisition to Model Deployment","heading":"2.2.1 Data Cleaning and Tidying","text":"Feature OTU tableTaxonomy tableMetadataMetabolic pathwaysOther experimental data…","code":""},{"path":"ml-framework_R.html","id":"exploratory-data-analysis","chapter":"2 Machine Learning Framework in R: From Data Acquisition to Model Deployment","heading":"2.2.2 Exploratory Data Analysis","text":"Diversity analysisTaxonomic profilingDifferential abundance analysisFunctional profiling","code":""},{"path":"ml-framework_R.html","id":"feature-engineering","chapter":"2 Machine Learning Framework in R: From Data Acquisition to Model Deployment","heading":"2.2.3 Feature Engineering","text":"Dimensionality reduction techniques (e.g., PCA, t-SNE)Feature selection methods (e.g., Boruta, LASSO)","code":""},{"path":"ml-framework_R.html","id":"model-development","chapter":"2 Machine Learning Framework in R: From Data Acquisition to Model Deployment","heading":"2.2.4 Model Development","text":"Selection appropriate machine learning algorithms (e.g., Random Forest, Support Vector Machines)Hyperparameter tuning using cross-validationModel evaluation metrics (e.g., accuracy, precision, recall, F1-score)","code":""},{"path":"ml-framework_R.html","id":"model-interpretation","chapter":"2 Machine Learning Framework in R: From Data Acquisition to Model Deployment","heading":"2.2.5 Model Interpretation","text":"Feature importance analysisVisualization model predictions (e.g., ROC curves, confusion matrices)","code":""},{"path":"ml-framework_R.html","id":"integration-with-biological-knowledge","chapter":"2 Machine Learning Framework in R: From Data Acquisition to Model Deployment","heading":"2.2.6 Integration with Biological Knowledge","text":"Interpretation model results context biological mechanismsIdentification potential biomarkers therapeutic targets","code":""},{"path":"ml-framework_R.html","id":"deployment-and-validation","chapter":"2 Machine Learning Framework in R: From Data Acquisition to Model Deployment","heading":"2.2.7 Deployment and Validation","text":"Application trained models new datasetsValidation model performance independent cohorts","code":""},{"path":"ml-framework_R.html","id":"model-framework-graphically","chapter":"2 Machine Learning Framework in R: From Data Acquisition to Model Deployment","heading":"2.3 Model Framework Graphically","text":", present visualization primary stages entailed constructing assessing machine learning model microbiome analysis.","code":""},{"path":"ml-framework_R.html","id":"data-preprocessing","chapter":"2 Machine Learning Framework in R: From Data Acquisition to Model Deployment","heading":"2.3.1 Data Preprocessing","text":"","code":"\nlibrary(DiagrammeR)\nlibrary(DiagrammeRsvg)\n\nmermaid(\"graph TD\n\nsubgraph A\n\nA[Data Cleaning and Transformation] --> B[Exploratory Analysis]\nB --> C[Feature Selection]\nC --> D[Feature Balancing]\nD --> E[Multi-Model Testing]\nend\n\n\", height = 800, width = 1000)"},{"path":"ml-framework_R.html","id":"model-development-1","chapter":"2 Machine Learning Framework in R: From Data Acquisition to Model Deployment","heading":"2.3.2 Model Development","text":"","code":"\nlibrary(DiagrammeR)\nlibrary(DiagrammeRsvg)\n\nmermaid(\"graph TD\n\nsubgraph B\n\nE[Machine Learning Model Development] --> F[Model Selection]\nF --> G[Parameters Tuning]\nG --> H[Parameter Cross-Validation]\nH --> I[Model Training]\nI --> J[Model Testing]\nend\n\n\", height = 800, width = 1000)"},{"path":"ml-framework_R.html","id":"model-evaluation-and-interpretation","chapter":"2 Machine Learning Framework in R: From Data Acquisition to Model Deployment","heading":"2.3.3 Model Evaluation and Interpretation","text":"","code":"\nlibrary(DiagrammeR)\nlibrary(DiagrammeRsvg)\n\nmermaid(\"graph TD\n\nsubgraph C\n\nJ[Model Evaluation and Interpretation] --> K[Performance Metrics]\nK --> L[Model Comparison]\nL --> M[Interpretation and Insights]\nM --> N[Deployment]\nN --> O[Validation]\nend\n\n\", height = 800, width = 1000)"},{"path":"ml-framework_R.html","id":"performance-metrics","chapter":"2 Machine Learning Framework in R: From Data Acquisition to Model Deployment","heading":"2.3.4 Performance metrics","text":"","code":"\nlibrary(DiagrammeR)\nlibrary(DiagrammeRsvg)\n\nmermaid(\"graph LR\n\nsubgraph D\n\nK{Model Evaluation} --> P[ROC: Receiver Operating Characteristic Curve]\nK --> Q[Precision Recall Curve]\nK --> R[F1 Score]\nK --> S[Confusion Matrix]\nK --> T[Accuracy]\nK --> U[Recall]\nK --> V[Precision]\nend\n\n\", height = 800, width = 1000)"},{"path":"machine-learning-prototypes-streamlining-microbiome-model-development-and-deployment.html","id":"machine-learning-prototypes-streamlining-microbiome-model-development-and-deployment","chapter":"3 Machine Learning Prototypes: Streamlining Microbiome Model Development and Deployment","heading":"3 Machine Learning Prototypes: Streamlining Microbiome Model Development and Deployment","text":"Machine Learning Prototypes (MLPs) serve foundational frameworks accelerating enhancing machine learning endeavors within context microbiome research. robust solutions offer streamlined approaches developing, deploying, monitoring machine learning models tailored specifically microbiome data analysis.","code":""},{"path":"machine-learning-prototypes-streamlining-microbiome-model-development-and-deployment.html","id":"key-features-of-ml-prototype","chapter":"3 Machine Learning Prototypes: Streamlining Microbiome Model Development and Deployment","heading":"3.1 Key Features of ML Prototype","text":"essential attributes characteristics MLPs:Robust Open-Source: MLPs robust, open-source solutions designed accelerate development deployment machine learning models.Robust Open-Source: MLPs robust, open-source solutions designed accelerate development deployment machine learning models.Comprehensive Frameworks: Fully developed MLPs empower Data Scientists providing comprehensive frameworks seamlessly build, deploy, monitor ML models.Comprehensive Frameworks: Fully developed MLPs empower Data Scientists providing comprehensive frameworks seamlessly build, deploy, monitor ML models.Tailored Common Use Cases: MLPs meticulously crafted around common industry use cases, Churn Prediction Monitoring Anomaly Detection, ensuring relevance applicability across diverse domains.Tailored Common Use Cases: MLPs meticulously crafted around common industry use cases, Churn Prediction Monitoring Anomaly Detection, ensuring relevance applicability across diverse domains.Built According Best Practices: MLPs developed according best practices, undergoing rigorous review testing guarantee reliability performance.Built According Best Practices: MLPs developed according best practices, undergoing rigorous review testing guarantee reliability performance.Reproducibility: MLPs designed reproducible, offering flexibility retrain models develop customized applications tailored specific needs.Reproducibility: MLPs designed reproducible, offering flexibility retrain models develop customized applications tailored specific needs.Advantageous Head Start: MLPs offer significant advantage providing head start machine learning development process.Advantageous Head Start: MLPs offer significant advantage providing head start machine learning development process.","code":""},{"path":"exploratory-data-analysis-eda.html","id":"exploratory-data-analysis-eda","chapter":"4 Exploratory Data Analysis (EDA)","heading":"4 Exploratory Data Analysis (EDA)","text":"machine learning start exploring data understand structure, patterns, relationships within data. involves visualizing distributions, correlations, relevant statistics gain insights dataset.","code":""},{"path":"exploratory-data-analysis-eda.html","id":"preprocessing-metagenomics-data","chapter":"4 Exploratory Data Analysis (EDA)","heading":"4.1 Preprocessing Metagenomics data","text":"Source: PRJEB13870. project titled “Gut microbiota dysbiosis contributes development hypertension” serves ideal resource metagenomics dataset. dataset offers valuable insights association gut microbiota composition hypertension development, critical area research within fields microbiology cardiovascular health.","code":""},{"path":"exploratory-data-analysis-eda.html","id":"load-necessary-libraries","chapter":"4 Exploratory Data Analysis (EDA)","heading":"4.1.1 Load necessary libraries","text":"","code":"\n# Load necessary libraries with suppressed startup messages\nlibrary(tidyverse, suppressPackageStartupMessages())\nlibrary(broom)\nlibrary(ggtext)\nlibrary(data.table)\n\n# Set seed for reproducibility\nset.seed(2022)"},{"path":"exploratory-data-analysis-eda.html","id":"processing-otu-table-data","chapter":"4 Exploratory Data Analysis (EDA)","heading":"4.1.2 Processing OTU table data","text":"","code":"\notutable <- readr::read_csv(\"data/HypertensionProject.csv\", show_col_types = FALSE) %>%\n  dplyr::select(1, Prevotella:ncol(.)) %>%\n  data.table::transpose(keep.names = \"taxonomy\", make.names = \"SampleID\") %>%\n  tidyr::pivot_longer(-taxonomy, names_to=\"sample_id\", values_to=\"rel_abund\") %>%\n  dplyr::relocate(sample_id)"},{"path":"exploratory-data-analysis-eda.html","id":"processing-metabolites-data","chapter":"4 Exploratory Data Analysis (EDA)","heading":"4.1.3 Processing metabolites data","text":"","code":"\nmetabolites <- read_csv(\"data/HypertensionProjectMetabolites.csv\", show_col_types = FALSE) %>%\n  dplyr::select(c(1, 5:ncol(.))) %>%\n  data.table::transpose(keep.names = \"metabopwy\", make.names = \"SampleID\") %>%\n  tidyr::pivot_longer(-metabopwy, names_to=\"sample_id\", values_to=\"value\") %>%\n  dplyr::group_by(sample_id) %>% \n  dplyr::mutate(rel_abund = value/sum(value)) %>% \n  dplyr::ungroup() %>% \n  dplyr::select(-value) %>% \n  dplyr::relocate(sample_id)"},{"path":"exploratory-data-analysis-eda.html","id":"processing-taxonomy-data","chapter":"4 Exploratory Data Analysis (EDA)","heading":"4.1.4 Processing taxonomy data","text":"","code":"\ntaxonomy <- readr::read_tsv(\"data/mo_demodata/baxter.cons.taxonomy\", show_col_types = FALSE) %>%\n  dplyr::rename_all(tolower) %>%\n  dplyr::select(otu, taxonomy) %>%\n  dplyr::mutate(taxonomy = stringr::str_replace_all(taxonomy, \"\\\\(\\\\d+\\\\)\", \"\"),\n         taxonomy = stringr::str_replace(taxonomy, \";unclassified\", \"_unclassified\"),\n         taxonomy = stringr::str_replace_all(taxonomy, \";unclassified\", \"\"),\n         taxonomy = stringr::str_replace_all(taxonomy, \";$\", \"\"),\n         taxonomy = stringr::str_replace_all(taxonomy, \".*;\", \"\"))"},{"path":"exploratory-data-analysis-eda.html","id":"processing-metadata","chapter":"4 Exploratory Data Analysis (EDA)","heading":"4.1.5 Processing metadata","text":"","code":"\nmetadata <- readr::read_csv(\"data/HypertensionProject.csv\", show_col_types = FALSE) %>%\n  dplyr::select(c(1:3)) %>%\n  dplyr::mutate(hyper = Disease_State == \"HTN\" | Disease_State == \"pHTN\",\n         control = Disease_State == \"healthy\") %>%\n  dplyr::rename(sample_id = SampleID)"},{"path":"exploratory-data-analysis-eda.html","id":"joining-metagenomics-data","chapter":"4 Exploratory Data Analysis (EDA)","heading":"4.2 Joining metagenomics data","text":"","code":""},{"path":"exploratory-data-analysis-eda.html","id":"join-metadata-with-otu-table","chapter":"4 Exploratory Data Analysis (EDA)","heading":"4.2.1 Join metadata with OTU table","text":"","code":"# Join metadata with OTU table to create composite dataset\ncomposite <- dplyr::inner_join(metadata, otutable, by=\"sample_id\")\nhead(composite)\n# A tibble: 6 × 7\n  sample_id  Disease_State Enterotype   hyper control taxonomy         rel_abund\n  <chr>      <chr>         <chr>        <lgl> <lgl>   <chr>                <dbl>\n1 ERR1398068 HTN           Enterotype_1 TRUE  FALSE   Prevotella         5.53e-1\n2 ERR1398068 HTN           Enterotype_1 TRUE  FALSE   Faecalibacterium   1.70e-2\n3 ERR1398068 HTN           Enterotype_1 TRUE  FALSE   Klebsiella         2.99e-6\n4 ERR1398068 HTN           Enterotype_1 TRUE  FALSE   Roseburia          7.47e-3\n5 ERR1398068 HTN           Enterotype_1 TRUE  FALSE   Bifidobacterium    1.92e-3\n6 ERR1398068 HTN           Enterotype_1 TRUE  FALSE   Enterobacter       8.52e-7"},{"path":"exploratory-data-analysis-eda.html","id":"join-metadata-with-metabolites-data","chapter":"4 Exploratory Data Analysis (EDA)","heading":"4.2.2 Join metadata with metabolites data","text":"","code":"# Join metadata with metabolites data to create composite metabolites dataset\nmetabo_composite <- dplyr::inner_join(metadata, metabolites, by=\"sample_id\")\nhead(metabo_composite)\n# A tibble: 6 × 7\n  sample_id  Disease_State Enterotype   hyper control metabopwy        rel_abund\n  <chr>      <chr>         <chr>        <lgl> <lgl>   <chr>                <dbl>\n1 ERR1398068 HTN           Enterotype_1 TRUE  FALSE   LPS_biosynthesis 0.00962  \n2 ERR1398068 HTN           Enterotype_1 TRUE  FALSE   LPS_transport    0.0000221\n3 ERR1398068 HTN           Enterotype_1 TRUE  FALSE   PTS              0.203    \n4 ERR1398068 HTN           Enterotype_1 TRUE  FALSE   Secretion_Syste… 0.0000221\n5 ERR1398068 HTN           Enterotype_1 TRUE  FALSE   Secretion_Syste… 0        \n6 ERR1398068 HTN           Enterotype_1 TRUE  FALSE   Secretion_Syste… 0.000375 "},{"path":"exploratory-data-analysis-eda.html","id":"preprocessing-microbiome-data","chapter":"4 Exploratory Data Analysis (EDA)","heading":"4.3 Preprocessing microbiome data","text":"outline steps involved processing integrating microbiome (16S rRNA) OTU table, taxonomy data, metadata, please refer imap-data-preparation. primary dataset sourced publicly available Dietswap dataset, retrieved microbiome package. dataset preprocessed integrated long-form dataframe format already.","code":""},{"path":"exploratory-data-analysis-eda.html","id":"import-preprocessed-microbiome-data","chapter":"4 Exploratory Data Analysis (EDA)","heading":"4.3.1 Import preprocessed microbiome data","text":"","code":"# Using dietswap dataset from microbiome package\ncp ../imap-data-preparation/data/phyloseq_raw_rel_psextra_df_objects.rda data"},{"path":"exploratory-data-analysis-eda.html","id":"load-saved-data-objects","chapter":"4 Exploratory Data Analysis (EDA)","heading":"4.3.2 Load saved data objects","text":"","code":"load(\"data/phyloseq_raw_rel_psextra_df_objects.rda\", verbose = TRUE)\nLoading objects:\n  ps_raw\n  ps_rel\n  psextra_raw\n  psextra_rel\n  ps_df"},{"path":"exploratory-data-analysis-eda.html","id":"view-phyloseq-object","chapter":"4 Exploratory Data Analysis (EDA)","heading":"4.3.3 View phyloseq object","text":"","code":"ps_raw\nphyloseq-class experiment-level object\notu_table()   OTU Table:         [ 130 taxa and 222 samples ]\nsample_data() Sample Data:       [ 222 samples by 8 sample variables ]\ntax_table()   Taxonomy Table:    [ 130 taxa by 3 taxonomic ranks ]\nphy_tree()    Phylogenetic Tree: [ 130 tips and 129 internal nodes ]"},{"path":"exploratory-data-analysis-eda.html","id":"view-dataframe-structure","chapter":"4 Exploratory Data Analysis (EDA)","heading":"4.3.4 View dataframe structure","text":"","code":"head(ps_df[, c(1, 4, 9, 11, 12, 13)])\n# A tibble: 6 × 6\n  sample_id  nationality bmi        rel_abund level  taxon                      \n  <chr>      <fct>       <fct>          <dbl> <chr>  <chr>                      \n1 Sample-208 AFR         overweight     0.617 phylum *Bacteroidetes*            \n2 Sample-208 AFR         overweight     0.617 family *Bacteroidetes*            \n3 Sample-208 AFR         overweight     0.617 genus  *Prevotella melaninogenica*\n4 Sample-208 AFR         overweight     0.617 otu    *Prevotella melaninogenica*\n5 Sample-212 AFR         obese          0.702 phylum *Bacteroidetes*            \n6 Sample-212 AFR         obese          0.702 family *Bacteroidetes*            "},{"path":"exploratory-data-analysis-eda.html","id":"processing-data-for-machine-learning","chapter":"4 Exploratory Data Analysis (EDA)","heading":"4.4 Processing data for machine learning","text":"section outlines preprocessing steps involved preparing data subsets tailored machine learning analysis. code segments transform raw data structured formats suitable predictive modeling. Specifically, subsets created encompass various combinations taxonomic metabolic features alongside binary labels representing selected features. subset undergoes specific preprocessing steps, including data selection, transformation, encoding, ensure compatibility machine learning algorithms.","code":""},{"path":"exploratory-data-analysis-eda.html","id":"data-for-disease-state-prediction","chapter":"4 Exploratory Data Analysis (EDA)","heading":"4.4.1 Data for disease state prediction","text":"code snippet prepares dataset machine learning tasks. selects specific columns composite dataset, renames columns clarity, pivots data wider format, finally, transforms categorical variables binary ones modeling purposes. ’s brief description:","code":"library(dplyr)\nlibrary(tidyr)\n\n# Prepare dataset for machine learning\nml_genus_dsestate <- composite %>%\n  # Select relevant columns and rename them\n  select(sample_id, taxonomy, rel_abund, dsestate = Disease_State) %>%\n  # Pivot data to wider format\n  pivot_wider(names_from=taxonomy, values_from = rel_abund) %>%\n  # Remove sample_id\n  select(-sample_id) %>%\n  # Convert categorical variables to binary\n  mutate(dsestate = if_else(dsestate == \"pHTN\" | dsestate == \"HTN\" , \"0\", \"1\")) %>%\n  # Reorder columns with dsestate first\n  select(dsestate, everything())\n\nhead(ml_genus_dsestate[1:3, 1:5])\n# A tibble: 3 × 5\n  dsestate Prevotella Faecalibacterium Klebsiella Roseburia\n  <chr>         <dbl>            <dbl>      <dbl>     <dbl>\n1 0             0.553          0.0170  0.00000299   0.00747\n2 0             0.217          0.285   0.0000593    0.00236\n3 0             0.298          0.00443 0.00513      0.00751"},{"path":"exploratory-data-analysis-eda.html","id":"data-for-enterotype-prediction","chapter":"4 Exploratory Data Analysis (EDA)","heading":"4.4.2 Data for enterotype prediction","text":"","code":"\n# Subset for machine learning analysis: Taxonomic genus features with enterotypes\nml_genus_enttype <- composite %>%\n  select(sample_id, taxonomy, enttype = Enterotype, rel_abund, dsestate = Disease_State) %>%\n  pivot_wider(names_from=taxonomy, values_from = rel_abund) %>%\n  select(-sample_id) %>%\n  mutate(enttype = if_else(enttype == \"Enterotype_1\", \"0\", \"1\")) %>%\n  mutate(dsestate = if_else(dsestate == \"pHTN\" | dsestate == \"HTN\" , \"0\", \"1\")) %>%\n  select(-dsestate) %>%\n  select(enttype, everything())\n\nhead(ml_genus_enttype[1:3, 1:5])\n# A tibble: 3 × 5\n  enttype Prevotella Faecalibacterium Klebsiella Roseburia\n  <chr>        <dbl>            <dbl>      <dbl>     <dbl>\n1 0            0.553          0.0170  0.00000299   0.00747\n2 0            0.217          0.285   0.0000593    0.00236\n3 0            0.298          0.00443 0.00513      0.00751"},{"path":"exploratory-data-analysis-eda.html","id":"data-for-nationality-prediction","chapter":"4 Exploratory Data Analysis (EDA)","heading":"4.4.3 Data for nationality prediction","text":"","code":"# Dietswap dataset: Subset for machine learning analysis: Taxonomic genus features with nationality and body mass index group\n\n# Nationality feature\nml_genus_nationality <- ps_df %>%\n  select(sample_id, taxon, nationality, rel_abund) %>%\n  mutate(\n    taxon = str_replace_all(taxon, \"\\\\*\", \"\"),\n    nationality = factor(if_else(nationality == \"AAM\", \"0\", \"1\"), levels = c(\"0\", \"1\")),) %>%\n  group_by(sample_id, taxon, nationality) %>%\n  summarise(rel_abund = mean(rel_abund), .groups = \"drop\") %>%\n  pivot_wider(names_from = taxon, values_from = rel_abund) %>%\n  ungroup() %>%\n  filter(!is.na(nationality)) %>%  # Remove rows with NA in the 'nationality' column\n  select(-c(sample_id)) %>%\n  mutate(across(starts_with(\"rel_abund\"), as.numeric))\n\nhead(ml_genus_nationality[1:3, 1:5])\n# A tibble: 3 × 5\n  nationality Actinobacteria Akkermansia `Alcaligenes faecalis` Allistipes\n  <fct>                <dbl>       <dbl>                  <dbl>      <dbl>\n1 0                 0.00121      0.00213               0.000118    0.0397 \n2 1                 0.000533     0.00724               0.000406    0.00180\n3 1                 0.00123      0.136                 0.000420    0.00897"},{"path":"exploratory-data-analysis-eda.html","id":"data-for-body-mass-index-prediction","chapter":"4 Exploratory Data Analysis (EDA)","heading":"4.4.4 Data for body mass index prediction","text":"Dataset: Dietswap microbiome R package","code":"ml_genus_bmi <- ps_df %>%\n  select(sample_id, taxon, rel_abund, bmi) %>%\n  mutate(\n    taxon = str_replace_all(taxon, \"\\\\*\", \"\"),\n    bmi = factor(if_else(bmi == \"overweight\" | bmi == \"obese\", \"0\", \"1\"), levels = c(\"0\", \"1\"))\n  ) %>%\n  group_by(sample_id, taxon, bmi) %>%\n  summarise(rel_abund = mean(rel_abund), .groups = \"drop\") %>%\n  pivot_wider(names_from = taxon, values_from = rel_abund) %>%\n  ungroup() %>%\n  filter(!is.na(bmi)) %>%  # Remove rows with NA in the 'bmi' column\n  select(-c(sample_id)) %>%\n  mutate(across(starts_with(\"rel_abund\"), as.numeric))\n\nhead(ml_genus_bmi[1:3, 1:5])\n# A tibble: 3 × 5\n  bmi   Actinobacteria Akkermansia `Alcaligenes faecalis` Allistipes\n  <fct>          <dbl>       <dbl>                  <dbl>      <dbl>\n1 0           0.00121      0.00213               0.000118    0.0397 \n2 1           0.000533     0.00724               0.000406    0.00180\n3 1           0.00123      0.136                 0.000420    0.00897"},{"path":"exploratory-data-analysis-eda.html","id":"save-the-processed-data-into-rda-objects","chapter":"4 Exploratory Data Analysis (EDA)","heading":"4.4.5 Save the processed data into RDA objects","text":"\nNote users:\n\nencounter issues data processing pivot_wider()\nreturns values <list>, may due multiple values \ncombination identifiers (e.g., sample ID feature). \ncases, consider aggregating values using group_by() summarise()\npivoting.\n\nExample:\n\nps_df %>% select(sample_id, taxon, nationality, rel_abund, bmi)\n%>% mutate(taxon = str_replace_all(taxon, “*“,”“)) %>%\ngroup_by(sample_id, taxon, nationality, bmi) %>% summarise(rel_abund\n= mean(rel_abund), .groups =”drop”) %>% pivot_wider(names_from =\ntaxon, values_from = rel_abund) %>% mutate(nationality =\nif_else(nationality == “AAM”, “0”, “1”)) %>% mutate(bmi = if_else(bmi\n== “overweight” | bmi == “obese” , “0”, “1”)) %>%\nselect(-c(sample_id, bmi))\n\nensures rel_abund values properly aggregated \npivoting.\n","code":"\nsave(composite,\n     metabo_composite,\n     ml_genus_dsestate,\n     ps_df,\n     ml_genus_enttype, \n     ml_genus_nationality, \n     ml_genus_bmi, \n     file = \"data/ml_n_composite_object.rda\")"},{"path":"feature-engineering-1.html","id":"feature-engineering-1","chapter":"5 Feature Engineering","heading":"5 Feature Engineering","text":"Feature engineering crucial step machine learning pipeline raw data transformed format enhances performance predictive models. process involves creating new features, selecting relevant features, transforming existing features improve model’s ability capture patterns make accurate predictions.performing effective feature engineering, can improve performance, interpretability, robustness machine learning models, ultimately leading better predictions insights data.common techniques used feature engineering include feature creation, selection transformation.","code":""},{"path":"feature-engineering-1.html","id":"feature-creation-simplified-example","chapter":"5 Feature Engineering","heading":"5.1 Feature Creation (Simplified Example)","text":"Feature creation involves generating new features existing ones. can include extracting information text, dates, categorical variables, creating interaction terms variables.example: simplified example, demonstrate feature creation using demographic data., divide ages three groups based ‘age’ column create new feature called ‘age_group’. first load necessary libraries, create sample data containing information age, gender, income. create new feature called age_group based ‘age’ column, dividing ages three groups: “<30”, “30-40”, “>40”. Finally, display DataFrame new feature included.","code":""},{"path":"feature-engineering-1.html","id":"sample-dataframe","chapter":"5 Feature Engineering","heading":"5.1.1 Sample dataframe","text":"","code":"\n# Load necessary libraries\nlibrary(tidyverse)## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n## ✔ dplyr     1.1.4     ✔ readr     2.1.5\n## ✔ forcats   1.0.0     ✔ stringr   1.5.1\n## ✔ ggplot2   3.5.0     ✔ tibble    3.2.1\n## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n## ✔ purrr     1.0.2     \n## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n## ✖ dplyr::filter() masks stats::filter()\n## ✖ dplyr::lag()    masks stats::lag()\n## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n# Sample data\ndata <- tibble(\n  age = c(25, 30, 35, 40, 45),\n  gender = c('male', 'female', 'male', 'male', 'female'),\n  income = c(50000, 60000, 75000, 80000, 70000)\n)\n\n# Creating a DataFrame\ndf <- as_tibble(data)\nprint(df)## # A tibble: 5 × 3\n##     age gender income\n##   <dbl> <chr>   <dbl>\n## 1    25 male    50000\n## 2    30 female  60000\n## 3    35 male    75000\n## 4    40 male    80000\n## 5    45 female  70000"},{"path":"feature-engineering-1.html","id":"creating-a-new-feature-age_group","chapter":"5 Feature Engineering","heading":"5.1.2 Creating a new feature ‘age_group’","text":"example demonstrates feature creation using demographic data, principles apply various types data, including metagenomics microbiome data.","code":"\n# Feature creation example: creating a new feature 'age_group' based on age\ndf <- df %>%\n  mutate(age_group = cut(age, breaks = c(0, 30, 40, Inf), labels = c(\"<30\", \"30-40\", \">40\")))\n\n# Displaying the DataFrame with the new feature\nprint(df)## # A tibble: 5 × 4\n##     age gender income age_group\n##   <dbl> <chr>   <dbl> <fct>    \n## 1    25 male    50000 <30      \n## 2    30 female  60000 <30      \n## 3    35 male    75000 30-40    \n## 4    40 male    80000 30-40    \n## 5    45 female  70000 >40"},{"path":"feature-engineering-1.html","id":"feature-selection","chapter":"5 Feature Engineering","heading":"5.2 Feature Selection","text":"Identifying relevant features contribute predictive power model reducing dimensionality computational complexity.Objective: Perform feature selection identify relevant microbial taxa functional pathways associated binary outcome interest, disease status treatment response.Techniques: Utilize methods like Lasso regularization, Recursive Feature Elimination (RFE), Boruta algorithm automatically select important features penalize less informative ones, enhancing model interpretability performance.","code":""},{"path":"feature-engineering-1.html","id":"feature-selection-techniques","chapter":"5 Feature Engineering","heading":"5.3 Feature Selection Techniques","text":"Feature selection techniques aim identify relevant informative features modeling, reducing dimensionality data preserving predictive performance. Key techniques include:Variance Threshold: Eliminates features low variance, indicating little variability potentially less relevance target variable.Univariate Selection: Examines feature’s relationship target variable independently, selecting strongest statistical significance.Recursive Feature Elimination (RFE): Sequentially removes least important features, based model performance, optimal subset obtained.Principal Component Analysis (PCA): Projects original features lower-dimensional space, retaining critical information reducing dimensionality.Feature Importance: Determines importance features assessing contribution model performance. Techniques include Random Forest feature importance permutation importance.Correlation Analysis: Identifies relationships pairs features, helping detect redundant highly correlated variables.Forward/Backward Selection: Iteratively adds removes features model, based impact performance, arrive best subset.Least Absolute Shrinkage Selection Operator (LASSO): Penalizes absolute size feature coefficients, encouraging sparse solutions automatic feature selection.techniques facilitate creation efficient interpretable models focusing informative features reducing redundancy noise.","code":""},{"path":"feature-engineering-1.html","id":"demo-using-variance-threshold","chapter":"5 Feature Engineering","heading":"5.3.1 Demo using Variance threshold","text":"involves calculating variance feature.features whose variance exceeds predefined threshold selected.method useful filtering features low variance, indicating little variation data.","code":"\nlibrary(tidyverse)\nload(\"data/ml_n_composite_object.rda\", verbose = TRUE)## Loading objects:\n##   composite\n##   metabo_composite\n##   ml_genus_dsestate\n##   ps_df\n##   ml_genus_enttype\n##   ml_genus_nationality\n##   ml_genus_bmi\n# Example dataset (replace with your own data)\ndata <- ml_genus_nationality\n# data <- ml_genus_bmi\n# data <- ml_genus_enttype\n# data <- ml_genus_dsestate\n\n# Calculate variance for each feature\nvariances <- apply(data[, -1], 2, var)  # Exclude the first column (nationality)\n\n# Set the threshold for variance\nthreshold <- 0.0001  # Adjust as needed\n\n# Identify features with variance above the threshold\nselected_features <- names(variances[variances > threshold])\n\n# Remove NA values from selected_features\nselected_features <- selected_features[!is.na(selected_features)]\n\n# Add the first column (nationality) to the selected features\nselected_features <- c(\"nationality\", selected_features)\n\n# Filter dataset to include selected features\nfiltered_data <- data[, colnames(data) %in% selected_features]\n\n# Display filtered dataset\nhead(filtered_data[1:3, 1:5])## # A tibble: 3 × 5\n##   nationality Akkermansia Allistipes `Bacteroides fragilis` `Bacteroides ovatus`\n##   <fct>             <dbl>      <dbl>                  <dbl>                <dbl>\n## 1 0               0.00213    0.0397                 0.0524              0.0505  \n## 2 1               0.00724    0.00180                0.00151             0.000637\n## 3 1               0.136      0.00897                0.0729              0.00518"},{"path":"feature-engineering-1.html","id":"demo-using-correlation-analysis","chapter":"5 Feature Engineering","heading":"5.3.2 Demo using Correlation Analysis","text":"method involves calculating correlation feature target variable (another feature).Features selected based correlation coefficients.cutoff point correlation coefficient can set determine features considered relevant.Features correlation coefficients cutoff retained, discarded.Note: NA values must removed selected_features vector filtering dataset avoid errors.","code":"\n# Example dataset (replace with your own data)\ndata <- ml_genus_nationality\n\n# Calculate point-biserial correlation between each feature and the categorical target variable\ncorrelations <- sapply(data[-1], function(x) cor(x, as.numeric(data$nationality)))\n\n# Set the threshold for correlation\nthreshold <- 0.3  # Adjust as needed\n\n# Identify features with correlation above the threshold\nselected_features <- names(correlations[abs(correlations) > threshold])\n\n# Add the target variable (nationality) to the selected features\nselected_features <- c(\"nationality\", selected_features)\n\n# Filter dataset to include selected features\nfiltered_data <- data[, colnames(data) %in% selected_features]\n\n# Display filtered dataset\nhead(filtered_data[1:3, 1:5])## # A tibble: 3 × 5\n##   nationality Allistipes `Anaerostipes caccae` `Bacteroides fragilis`\n##   <fct>            <dbl>                 <dbl>                  <dbl>\n## 1 0              0.0397                0.0288                 0.0524 \n## 2 1              0.00180               0.00168                0.00151\n## 3 1              0.00897               0.00168                0.0729 \n## # ℹ 1 more variable: `Bacteroides ovatus` <dbl>"},{"path":"feature-engineering-1.html","id":"demo-with-wilcoxon-rank-sum-test","chapter":"5 Feature Engineering","heading":"5.3.3 Demo with Wilcoxon rank sum test","text":"Wilcoxon rank sum test, also known Mann-Whitney U test, nonparametric test used assess whether two independent samples different distributions. particularly useful assumptions t-test met, data normally distributed sample sizes smallDistribution significant generaCompute significant genera, thenP-values Adjusted P-values (p.adjust) can used measure significance levels.View distribution significant generaDistribution significant metabolic pathwaysCompute significant pathways, thenP-values Adjusted P-values (p.adjust) can used measure significance levels.View distribution significant pathways.filter metabolic pathways lesser stringent p.values (p < 0.25) demo purposes.","code":"\nlibrary(tidyverse)\nlibrary(broom)\n\nall_genera <- composite %>%\n  tidyr::nest(data = -taxonomy) %>%\n  mutate(test = purrr::map(data, ~wilcox.test(rel_abund ~ hyper, data = .x) %>% tidy)) %>%\n  tidyr::unnest(test) %>%\n  mutate(p.adjust = p.adjust(p.value, method = \"BH\"))\n\n\nsig_genera <- all_genera %>% \n  dplyr::filter(p.value < 0.001) %>%\n  arrange(p.adjust) %>% \n  dplyr::select(taxonomy, p.value)\nlibrary(tidyverse)\nlibrary(ggtext)\n\ncomposite %>%\n  inner_join(sig_genera, by=\"taxonomy\") %>%\n  mutate(rel_abund = 100 * (rel_abund + 1/20000),\n         taxonomy = str_replace(taxonomy, \"(.*)\", \"*\\\\1*\"),\n         taxonomy = str_replace(taxonomy, \"\\\\*(.*)_unclassified\\\\*\",\n                                \"Unclassified<br>*\\\\1*\"),\n         hyper = factor(hyper, levels = c(T, F))) %>%\n  ggplot(aes(x=rel_abund, y=taxonomy, color=hyper, fill=hyper)) +\n  # geom_vline(xintercept = 100/10530, size=0.5, color=\"gray\") +\n  geom_jitter(position = position_jitterdodge(dodge.width = 0.8,\n                                              jitter.width = 0.5),\n              shape=21) +\n  stat_summary(fun.data = median_hilow, fun.args = list(conf.int=0.5),\n               geom=\"pointrange\",\n               position = position_dodge(width=0.8),\n               color=\"black\", show.legend = FALSE) +\n  scale_x_log10() +\n  scale_color_manual(NULL,\n                     breaks = c(F, T),\n                     values = c(\"gray\", \"dodgerblue\"),\n                     labels = c(\"Control\", \"Hypertension\")) +\n  scale_fill_manual(NULL,\n                     breaks = c(F, T),\n                     values = c(\"gray\", \"dodgerblue\"),\n                     labels = c(\"Control\", \"Hypertension\")) +\n  labs(x= \"Relative abundance (%)\", y=NULL) +\n  theme_classic() +\n  theme(\n    axis.text.y = element_markdown()\n  )\nggsave(\"figures/significant_genera.tiff\", width=6, height=4)\nlibrary(tidyverse)\n\n# Compute the significant pathways using `wilcox.test`.\nall_metabopwy <- metabo_composite %>%\n  tidyr::nest(data = -metabopwy) %>%\n  mutate(test = purrr::map(.x=data, ~wilcox.test(rel_abund~hyper, data=.x) %>% tidy)) %>%\n  tidyr::unnest(test) %>%\n  mutate(p.adjust = p.adjust(p.value, method=\"BH\"))\n\nsig_metabopwy <- all_metabopwy %>% \n  dplyr::filter(p.value < 0.3) %>% # Typically, the best significant p-value is set at 0.05\n  dplyr::select(metabopwy, p.value)\nmetabo_composite %>%\n  inner_join(sig_metabopwy, by=\"metabopwy\") %>%\n  mutate(rel_abund = 100 * (rel_abund + 1/20000),\n         metabopwy = str_replace(metabopwy, \"(.*)\", \"*\\\\1*\"),\n         metabopwy = str_replace(metabopwy, \"\\\\*(.*)_unclassified\\\\*\",\n                                \"Unclassified<br>*\\\\1*\"),\n         hyper = factor(hyper, levels = c(T, F))) %>%\n  ggplot(aes(x=rel_abund, y=metabopwy, color=hyper, fill=hyper)) +\n  geom_jitter(position = position_jitterdodge(dodge.width = 0.8,\n                                              jitter.width = 0.5),\n              shape=21) +\n  stat_summary(fun.data = median_hilow, fun.args = list(conf.int=0.5),\n               geom=\"pointrange\",\n               position = position_dodge(width=0.8),\n               color=\"black\", show.legend = FALSE) +\n  scale_x_log10() +\n  scale_color_manual(NULL,\n                     breaks = c(F, T),\n                     values = c(\"gray\", \"dodgerblue\"),\n                     labels = c(\"Control\", \"Hypertension\")) +\n  scale_fill_manual(NULL,\n                     breaks = c(F, T),\n                     values = c(\"gray\", \"dodgerblue\"),\n                     labels = c(\"Control\", \"Hypertension\")) +\n  labs(x= \"Relative abundance (%)\", y=NULL) +\n  theme_classic() +\n  theme(\n    axis.text.y = element_markdown()\n  )\nggsave(\"figures/significant_genera.tiff\", width=6, height=4)"},{"path":"feature-engineering-1.html","id":"feature-transformation","chapter":"5 Feature Engineering","heading":"5.4 Feature Transformation:","text":"Applying transformations features make data suitable modeling.Scaling numeric features ensures features contribute equally analysis bringing similar scale.Encoding categorical variables converts categorical data numerical format, allowing algorithms work categorical data.Handling missing values involves strategies imputation removal missing data ensure completeness dataset.","code":"library(tidyverse)\n\n# Load the dataset\ndata <- ml_genus_nationality %>% \n  dplyr::rename(target = nationality)\n\n# Check for missing values\nmissing_values <- colSums(is.na(data))\n\n# Impute missing values with zeros\ndata_imputed <- replace(data, is.na(data), 0)\n\n# Display the first few rows of the imputed dataset\nhead(data_imputed[1:3, 1:5])\n# A tibble: 3 × 5\n  target Actinobacteria Akkermansia `Alcaligenes faecalis` Allistipes\n  <fct>           <dbl>       <dbl>                  <dbl>      <dbl>\n1 0            0.00121      0.00213               0.000118    0.0397 \n2 1            0.000533     0.00724               0.000406    0.00180\n3 1            0.00123      0.136                 0.000420    0.00897\n\nsave(data_imputed, file = \"data/data_imputed.rda\")"},{"path":"data-splitting.html","id":"data-splitting","chapter":"6 Data Splitting","heading":"6 Data Splitting","text":"dataset divided separate subsets training testing. partitioning allows unbiased evaluation model’s performance unseen data, helping assess ability generalize new observations.","code":""},{"path":"data-splitting.html","id":"load-necessary-libraries-1","chapter":"6 Data Splitting","heading":"6.1 Load necessary libraries","text":"","code":"\nset.seed(1234)\n\n\n\n# Load necessary libraries\nlibrary(caret)\nlibrary(tidyverse)\n\n# Example dataset (replace with your own data)\n\nload(\"data/data_imputed.rda\")\ndata <- data_imputed #%>%\n  # mutate(target_text = dplyr::recode_factor(target, \"0\" = \"AAM\", \"1\" = \"AFR\"), .after = 1)"},{"path":"data-splitting.html","id":"split-using-caretcreatedatapartition","chapter":"6 Data Splitting","heading":"6.2 Split using caret::createDataPartition()","text":"","code":"\n# Split data into training and testing sets\nset.seed(123) # for reproducibility\ntrain_index <- caret::createDataPartition(data$target, p = 0.8, list = FALSE)\ntrain_data <- data[train_index, ]\ntest_data <- data[-train_index, ]\n\nwrite_csv(test_data, \"models/test_data.csv\")\n\nsave(train_data, test_data, file = \"data/train_test_data.rda\")"},{"path":"data-splitting.html","id":"review-train-and-test-datasets","chapter":"6 Data Splitting","heading":"6.3 Review train and test datasets","text":"","code":"cat(\"\\nDimension of the train data using caret package\\n is\", base::dim(train_data)[1], \"rows and\", base::dim(train_data)[2], \"columns.\\n\")\n\nDimension of the train data using caret package\n is 179 rows and 144 columns.\ncat(\"\\nDimension of the test data using caret package\\n is\", base::dim(test_data)[1], \"rows and\", base::dim(test_data)[2], \"columns.\\n\")\n\nDimension of the test data using caret package\n is 43 rows and 144 columns.\n\ncat(\"\\nThe intersection between test and train dataset is\", nrow(test_data %>% intersect(train_data)))\n\nThe intersection between test and train dataset is 0"},{"path":"data-splitting.html","id":"spliting-using-dplyrsample_n-and-dplyrsetdiff-functions","chapter":"6 Data Splitting","heading":"6.4 Spliting using dplyr::sample_n() and dplyr::setdiff() functions**","text":"","code":"set.seed(123)\n\nlibrary(dplyr)\ntest_df = train_data %>% dplyr::sample_n(0.2*nrow(train_data))\ntrain_df = train_data %>% dplyr::setdiff(test_df)\n\ncat(\"\\nDimension of the test data using dplyr package\\n is\", base::dim(test_df)[1], \"rows and\", base::dim(test_df)[2], \"columns.\\n\")\n\nDimension of the test data using dplyr package\n is 35 rows and 144 columns.\ncat(\"\\nDimension of the train data using dplyr package\\n is\", base::dim(train_df)[1], \"rows and\", base::dim(train_df)[2], \"columns.\\n\")\n\nDimension of the train data using dplyr package\n is 144 rows and 144 columns.\n\ncat(\"\\nThe intersection between test and train dataset is\", nrow(test_df %>% intersect(train_df)))\n\nThe intersection between test and train dataset is 0"},{"path":"data-splitting.html","id":"relative-abundance-in-training-and-testing-datasets","chapter":"6 Data Splitting","heading":"6.5 Relative abundance in training and testing datasets","text":"","code":"\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(ggpubr)\n\ncols <- c(\"0\" = \"red\",\"1\" = \"green4\")\n\np1 <- train_data %>% ggplot(aes(x = `Bacteroides vulgatus`, y = `Prevotella melaninogenica`, color = factor(target))) + geom_point(size = 2, shape = 16, alpha = 0.6) +\n  labs(title = \"Relative Abundance in Train Dataset using \\ncaret::createDataPartition() function\") +\n  scale_colour_manual(values = cols, labels = c(\"African American\", \"Africa\"), name=\"Level\") +\n  theme_bw() +\n  theme(text = element_text(size = 8))\n\np2 <- test_data %>% ggplot(aes(x = `Bacteroides vulgatus`, y = `Prevotella melaninogenica`, color = factor(target))) + geom_point(size = 2, shape = 16, alpha = 0.6) +\n  labs(title = \"Relative Abundance in Test Dataset using \\ncaret::createDataPartition() function\") +\n  scale_colour_manual(values = cols, labels = c(\"African American\", \"Africa\"), name=\"Level\") +\n  theme_bw() +\n  theme(text = element_text(size = 8))\n\n\np3 <- train_df %>% ggplot(aes(x = `Bacteroides vulgatus`, y = `Prevotella melaninogenica`, color = factor(target))) + geom_point(size = 2, shape = 16, alpha = 0.6) +\n  labs(title = \"Relative Abundance in Train Dataset using \\ndplyr::sample_n() and dplyr::setdiff() functions\") +\n  scale_colour_manual(values = cols, labels = c(\"African American\", \"African\"), name=\"Level\") +\n  theme_bw() +\n  theme(text = element_text(size = 8))\n\np4 <- test_df %>% ggplot(aes(x = `Bacteroides vulgatus`, y = `Prevotella melaninogenica`, color = factor(target))) + geom_point(size = 2, shape = 16, alpha = 0.6) +\n  labs(title = \"Relative Abundance in Test Dataset using \\ndplyr::sample_n() and dplyr::setdiff() functions\") +\n  scale_colour_manual(values = cols, labels = c(\"African American\", \"African\"), name=\"Level\") +\n  theme_bw() +\n  theme(text = element_text(size = 8))\n\n# Arrange plots using ggpubr\nggarrange(p1, p2, p3, p4, nrow = 2, ncol = 2, common.legend = TRUE, legend = \"right\", heights = c(1, 1))"},{"path":"model-fitting.html","id":"model-fitting","chapter":"7 Model Fitting","heading":"7 Model Fitting","text":"Microbiome data presents unique challenges opportunities modeling due high dimensionality complexity. section, explore various algorithms suitable modeling microbiome datasets.","code":"\nif(!dir.exists(\"models\")) {dir.create(\"models\")}"},{"path":"model-fitting.html","id":"regularized-logistic-regression-model","chapter":"7 Model Fitting","heading":"7.1 Regularized Logistic Regression Model","text":"Regularized Logistic Regression (RLR) variant logistic regression tailored binary classification tasks commonly encountered microbiome studies. introduces penalty terms Lasso (L1) Ridge (L2) control model complexity prevent overfitting.","code":"set.seed(1234)\nlibrary(ggplot2)\n\nmod_regLogistic_cv <- train(target ~ ., data = train_data,\n                            method = \"regLogistic\",\n                            tuneLength = 12,\n                            trControl = caret::trainControl(method = \"adaptive_cv\",\n                                                             verboseIter = FALSE),\n                            tuneGrid = base::expand.grid(cost = seq(0.001, 1, length.out = 20),\n                                                         loss =  \"L2_primal\",\n                                                         epsilon = 0.01 ))\n\nprint(head(capture.output(mod_regLogistic_cv), n = 15), quote = FALSE)\n [1] Regularized Logistic Regression                                    \n [2]                                                                    \n [3] 179 samples                                                        \n [4] 143 predictors                                                     \n [5]   2 classes: '0', '1'                                              \n [6]                                                                    \n [7] No pre-processing                                                  \n [8] Resampling: Adaptively Cross-Validated (10 fold, repeated 1 times) \n [9] Summary of sample sizes: 161, 162, 161, 161, 161, 161, ...         \n[10] Resampling results across tuning parameters:                       \n[11]                                                                    \n[12]   cost        Accuracy   Kappa      Resamples                      \n[13]   0.00100000  0.5725490  0.0744186   5                             \n[14]   0.05357895  0.6813725  0.3315495   6                             \n[15]   0.10615789  0.7096950  0.4041659   6                             \n\n\n# Plot Accuracy vs. cost for Regularized Logistic Regression Model (Adaptive CV)\nggplot(mod_regLogistic_cv$results, aes(x = cost, y = Accuracy)) +\n  geom_line(color = \"blue\") +\n  geom_point(color = \"black\") +\n  labs(title = \"Accuracy vs. Cost for \\nRegularized Logistic Regression Model (Adaptive CV)\",\n       x = \"Cost\", y = \"Accuracy\") +\n  theme_bw()"},{"path":"model-fitting.html","id":"generalized-linear-models-glmnet","chapter":"7 Model Fitting","heading":"7.2 Generalized Linear Models (glmnet)","text":"glmnet package R fits Generalized Linear Models Lasso Elastic-Net regularization. ’s particularly useful microbiome data analysis due ability handle high-dimensional datasets sparse features.","code":"set.seed(1234)\nmod_glmnet_adcv <- train(target ~ ., data = train_data,\n             method = \"glmnet\",\n             tuneLength = 12,\n             trControl = caret::trainControl(method = \"adaptive_cv\"))\n\nprint(head(capture.output(mod_glmnet_adcv), n = 15), quote = FALSE)\n [1] glmnet                                                             \n [2]                                                                    \n [3] 179 samples                                                        \n [4] 143 predictors                                                     \n [5]   2 classes: '0', '1'                                              \n [6]                                                                    \n [7] No pre-processing                                                  \n [8] Resampling: Adaptively Cross-Validated (10 fold, repeated 1 times) \n [9] Summary of sample sizes: 161, 162, 161, 161, 161, 161, ...         \n[10] Resampling results across tuning parameters:                       \n[11]                                                                    \n[12]   alpha      lambda        Accuracy   Kappa       Resamples        \n[13]   0.1000000  0.0001194437  0.9437908  0.88870667   5               \n[14]   0.1000000  0.0002425803  0.9437908  0.88870667   5               \n[15]   0.1000000  0.0004926607  0.9437908  0.88870667   5               \n\nset.seed(1234)\n## Visualize the model performance\n\nlibrary(ggplot2)\n\n# Plot Accuracy vs. lambda for glmnet Model (Adaptive CV)\nggplot(mod_glmnet_adcv$results, aes(x = lambda, y = Accuracy)) +\n  geom_line(color = \"blue\") +\n  geom_point(color = \"black\") +\n  labs(title = \"Accuracy vs. Lambda for \\nglmnet Model (Adaptive CV)\",\n       x = \"Lambda\", y = \"Accuracy\") +\n  theme_bw()"},{"path":"model-fitting.html","id":"random-forest","chapter":"7 Model Fitting","heading":"7.3 Random Forest","text":"Random Forest ensemble learning technique combines multiple decision trees improve predictive performance. ’s well-suited handling high-dimensional nonlinear nature microbiome data mitigating overfitting.Random Forest model performance training (using metrics like accuracy)","code":"set.seed(1234)\nmod_rf_reptcv <- train(target ~ ., data = train_data,\n             method = \"rf\",\n             tuneLength = 12,\n             trControl = caret::trainControl(method = \"repeatedcv\"))\n\nprint(head(capture.output(mod_rf_reptcv), n = 15), quote = FALSE)\n [1] Random Forest                                              \n [2]                                                            \n [3] 179 samples                                                \n [4] 143 predictors                                             \n [5]   2 classes: '0', '1'                                      \n [6]                                                            \n [7] No pre-processing                                          \n [8] Resampling: Cross-Validated (10 fold, repeated 1 times)    \n [9] Summary of sample sizes: 161, 162, 161, 161, 161, 161, ... \n[10] Resampling results across tuning parameters:               \n[11]                                                            \n[12]   mtry  Accuracy   Kappa                                   \n[13]     2   0.9663399  0.9322683                               \n[14]    14   0.9549020  0.9085759                               \n[15]    27   0.9493464  0.8980417                               \n\n## Visualize the model performance\n\nlibrary(ggplot2)\n\n\n# Plot Accuracy vs. mtry for Random Forest Model (Repeated CV)\nggplot(mod_rf_reptcv$results, aes(x = mtry, y = Accuracy)) +\n  geom_line(color = \"blue\") +\n  geom_point(color = \"black\") +\n  labs(title = \"Accuracy vs. mtry for Random Forest Model (Repeated CV)\",\n       x = \"mtry\", y = \"Accuracy\") +\n  theme_bw()set.seed(1234)\n## Visualize the model performance\n\n\nmod_rf_adcv <- train(target ~ ., data = train_data,\n             method = \"rf\",\n             tuneLength = 12,\n             trControl = caret::trainControl(method = \"adaptive_cv\",\n                      verboseIter = FALSE))\n\nprint(head(capture.output(mod_rf_adcv), n = 15), quote = FALSE)\n [1] Random Forest                                                      \n [2]                                                                    \n [3] 179 samples                                                        \n [4] 143 predictors                                                     \n [5]   2 classes: '0', '1'                                              \n [6]                                                                    \n [7] No pre-processing                                                  \n [8] Resampling: Adaptively Cross-Validated (10 fold, repeated 1 times) \n [9] Summary of sample sizes: 161, 162, 161, 161, 161, 161, ...         \n[10] Resampling results across tuning parameters:                       \n[11]                                                                    \n[12]   mtry  Accuracy   Kappa      Resamples                            \n[13]     2   0.9663399  0.9322683  10                                   \n[14]    14   0.9542484  0.9072082   5                                   \n[15]    27   0.9431373  0.8849859   5                                   \n\nlibrary(ggplot2)\n\n# Plot Accuracy vs. mtry for Random Forest Model (Adaptive CV)\nggplot(mod_rf_adcv$results, aes(x = mtry, y = Accuracy)) +\n  geom_line(color = \"blue\") +\n  geom_point(color = \"black\") +\n  labs(title = \"Accuracy vs. mtry for Random Forest Model (Adaptive CV)\",\n       x = \"mtry\", y = \"Accuracy\") +\n  theme_bw()"},{"path":"model-fitting.html","id":"k-nearest-neighbors-knn","chapter":"7 Model Fitting","heading":"7.4 k-Nearest Neighbors (kNN)","text":"kNN simple yet effective algorithm classification regression tasks microbiome studies. works assigning class label unclassified sample based majority class k nearest neighbors feature space.k-Nearest Neighbors model performance training (using metrics like accuracy)","code":"set.seed(1234)\nmod_knn_reptcv <- train(target ~ ., data = train_data,\n                        method = \"knn\",\n                        tuneLength = 12,\n                        trControl = caret::trainControl(method = \"repeatedcv\",\n                                                         repeats = 2))\nprint(head(capture.output(mod_knn_reptcv), n = 15), quote = FALSE)\n [1] k-Nearest Neighbors                                        \n [2]                                                            \n [3] 179 samples                                                \n [4] 143 predictors                                             \n [5]   2 classes: '0', '1'                                      \n [6]                                                            \n [7] No pre-processing                                          \n [8] Resampling: Cross-Validated (10 fold, repeated 2 times)    \n [9] Summary of sample sizes: 161, 162, 161, 161, 161, 161, ... \n[10] Resampling results across tuning parameters:               \n[11]                                                            \n[12]   k   Accuracy   Kappa                                     \n[13]    5  0.8153595  0.6319367                                 \n[14]    7  0.8125817  0.6284433                                 \n[15]    9  0.8066993  0.6175578                                 \n\nlibrary(ggplot2)\n\n# Plot Accuracy vs. k for KNN Model (Repeated CV)\nggplot(mod_knn_reptcv$results, aes(x = k, y = Accuracy)) +\n  geom_line(color = \"blue\") +\n  geom_point(color = \"black\") +\n  labs(title = \"Accuracy vs. k for KNN Model (Repeated CV)\",\n       x = \"k\", y = \"Accuracy\") +\n  theme_bw()set.seed(1234)\n## Visualize the model performance\n\nlibrary(ggplot2)\n\nmod_knn_adcv <- train(target ~ ., data = train_data,\n                      method = \"knn\",\n                      tuneLength = 12,\n                      trControl = caret::trainControl(method = \"adaptive_cv\",\n                                                       repeats = 2,\n                                                       verboseIter = FALSE))\n\nprint(head(capture.output(mod_knn_adcv), n = 15), quote = FALSE)\n [1] k-Nearest Neighbors                                                \n [2]                                                                    \n [3] 179 samples                                                        \n [4] 143 predictors                                                     \n [5]   2 classes: '0', '1'                                              \n [6]                                                                    \n [7] No pre-processing                                                  \n [8] Resampling: Adaptively Cross-Validated (10 fold, repeated 2 times) \n [9] Summary of sample sizes: 161, 162, 161, 161, 161, 161, ...         \n[10] Resampling results across tuning parameters:                       \n[11]                                                                    \n[12]   k   Accuracy   Kappa      Resamples                              \n[13]    5  0.8153595  0.6319367  20                                     \n[14]    7  0.7997199  0.6000193   7                                     \n[15]    9  0.8028322  0.6086850   6                                     \n\n# Plot Accuracy vs. k for KNN Model (Adaptive CV)\nggplot(mod_knn_adcv$results, aes(x = k, y = Accuracy)) +\n  geom_line(color = \"blue\") +\n  geom_point(color = \"black\") +\n  labs(title = \"Accuracy vs. k for KNN Model (Adaptive CV)\",\n       x = \"k\", y = \"Accuracy\") +\n  theme_bw()"},{"path":"model-fitting.html","id":"decision-trees","chapter":"7 Model Fitting","heading":"7.5 Decision Trees","text":"Decision Trees offer intuitive approach modeling microbiome data recursively partitioning feature space based microbial abundance levels. susceptible overfitting, decision trees provide insights hierarchical structure microbiome communities.","code":""},{"path":"model-fitting.html","id":"support-vector-machines-svm","chapter":"7 Model Fitting","heading":"7.6 Support Vector Machines (SVM)","text":"SVM powerful algorithm classifying microbiome samples based microbial composition. finding optimal hyperplane separates different microbial communities, SVM can effectively discern complex patterns microbiome data.","code":""},{"path":"model-fitting.html","id":"neural-networks","chapter":"7 Model Fitting","heading":"7.7 Neural Networks","text":"Neural Networks, including Deep Learning architectures, offer flexible framework modeling microbiome datasets. models can capture intricate relationships microbial taxa host phenotypes, making valuable tasks disease classification biomarker discovery.","code":""},{"path":"model-fitting.html","id":"gradient-boosting-machines-gbm","chapter":"7 Model Fitting","heading":"7.8 Gradient Boosting Machines (GBM)","text":"GBM ensemble learning method builds sequence decision trees gradually improve predictive accuracy. ’s adept handling complex interactions microbial taxa host factors, making suitable microbiome classification tasks.","code":""},{"path":"model-fitting.html","id":"adaboost","chapter":"7 Model Fitting","heading":"7.9 AdaBoost","text":"AdaBoost boosting algorithm combines multiple weak learners create strong classifier. ’s particularly useful microbiome data classification due ability focus difficult--classify samples improve overall model performance.","code":""},{"path":"model-fitting.html","id":"naive-bayes","chapter":"7 Model Fitting","heading":"7.10 Naive Bayes","text":"Naive Bayes probabilistic classifier based Bayes’ theorem assumption independence features. simplicity makes computationally efficient, Naive Bayes can still provide competitive performance microbiome classification tasks.\ncertain models utilize lambda, Regularized Logistic\nRegression models, capability set lambda using\nexpressions define sequence numerical values. instance,\nemploying expression 10^seq(-3, 3, = 0.5) results \ngeneration numbers raising 10 power element\nwithin sequence ranging -3 3, increment 0.5. \noutput presents sequence values, 10^-3, 10^-2.5, 10^-2,\n10^-1.5, 10^-1, 10^-0.5, 10^0, 10^0.5, 10^1, 10^1.5, 10^2, 10^2.5, \n10^3.\n","code":"\nsave(mod_glmnet_adcv, mod_regLogistic_cv, mod_rf_adcv, mod_rf_reptcv, mod_knn_adcv, mod_knn_reptcv, file = \"models/models.rda\")"},{"path":"model-evaluation.html","id":"model-evaluation","chapter":"8 Model Evaluation","heading":"8 Model Evaluation","text":"Model evaluation involves assessing performance machine learning model using various metrics techniques.","code":""},{"path":"model-evaluation.html","id":"performance-metrics-1","chapter":"8 Model Evaluation","heading":"8.1 Performance Metrics","text":"","code":""},{"path":"model-evaluation.html","id":"confusion-matrix","chapter":"8 Model Evaluation","heading":"8.1.1 Confusion Matrix","text":"table used describe performance classification model, showing counts true positive, true negative, false positive, false negative predictions.","code":"load(\"data/data_imputed.rda\", verbose = TRUE)\nLoading objects:\n  data_imputed\nload(\"data/train_test_data.rda\", verbose = TRUE)\nLoading objects:\n  train_data\n  test_data\nload(\"models/models.rda\", verbose = TRUE)\nLoading objects:\n  mod_glmnet_adcv\n  mod_regLogistic_cv\n  mod_rf_adcv\n  mod_rf_reptcv\n  mod_knn_adcv\n  mod_knn_reptcv\n# Load necessary libraries\nlibrary(caret)\n# Predict using the trained model\npredictions <- predict(mod_regLogistic_cv, newdata = test_data)\n\n# Compute confusion matrix\nconfusion_matrix <- caret::confusionMatrix(predictions, test_data$target)\n\nprint(confusion_matrix)\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  0  1\n         0 19  3\n         1  5 16\n                                         \n               Accuracy : 0.814          \n                 95% CI : (0.666, 0.9161)\n    No Information Rate : 0.5581         \n    P-Value [Acc > NIR] : 0.000393       \n                                         \n                  Kappa : 0.6269         \n                                         \n Mcnemar's Test P-Value : 0.723674       \n                                         \n            Sensitivity : 0.7917         \n            Specificity : 0.8421         \n         Pos Pred Value : 0.8636         \n         Neg Pred Value : 0.7619         \n             Prevalence : 0.5581         \n         Detection Rate : 0.4419         \n   Detection Prevalence : 0.5116         \n      Balanced Accuracy : 0.8169         \n                                         \n       'Positive' Class : 0              \n                                         "},{"path":"model-evaluation.html","id":"accuracy","chapter":"8 Model Evaluation","heading":"8.1.2 Accuracy","text":"proportion correctly classified instances total instances.","code":"\nlibrary(caret)\naccuracy <- confusion_matrix$overall[\"Accuracy\"]\naccuracy\n Accuracy \n0.8139535 "},{"path":"model-evaluation.html","id":"precision","chapter":"8 Model Evaluation","heading":"8.1.3 Precision","text":"proportion true positive predictions positive predictions. measures model’s ability identify relevant instances.","code":"\nlibrary(caret)\nprecision <- confusion_matrix$byClass[\"Precision\"]\n\nprint(precision)\nPrecision \n0.8636364 "},{"path":"model-evaluation.html","id":"recall-sensitivity","chapter":"8 Model Evaluation","heading":"8.1.4 Recall (Sensitivity)","text":"proportion true positive predictions actual positive instances. measures model’s ability capture positive instances.","code":"\nlibrary(caret)\nrecall <- confusion_matrix$byClass[\"Recall\"]\nprint(recall)\n   Recall \n0.7916667 "},{"path":"model-evaluation.html","id":"f1-score","chapter":"8 Model Evaluation","heading":"8.1.5 F1 Score","text":"harmonic mean precision recall, providing balance two metrics. useful class distribution imbalanced.Performance metrics dataframeVisualize model performance metrics\nFunction computing Specificity \nSensitivity\n\nlibrary(purrr)\n\nget_sens_spec <- function(threshold, score, actual,\ndirection){\n\npredicted <- (direction == “greaterthan”) { score > threshold\n} else { score < threshold }\n\ntp <- sum(predicted & actual) tn <- sum(!predicted &\n!actual) fp <- sum(predicted & !actual) fn <- sum(!predicted\n& actual)\n\nspecificity <- tn / (tn + fp) sensitivity <- tp / (tp + fn)\n\ntibble(“specificity” = specificity, “sensitivity” = sensitivity)\n}\n\nget_roc_data <- function(x, direction){\n\n# x <- test # direction <- “greaterthan”\n\nthresholds <- unique(x$score) %>% sort()\n\nmap_dfr(.x=thresholds, ~get_sens_spec(.x, x\\(score, x\\)srn, direction)) %>%\nrbind(c(specificity = 0, sensitivity = 1)) }\n","code":"\nlibrary(caret)\nf1 <- confusion_matrix$byClass[\"F1\"]\nprint(f1)\n      F1 \n0.826087 # Create a data frame for model performance metrics\nperformance_metrics <- data.frame(\n  Metric = c(\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"),\n  Value = c(accuracy, precision, recall, f1)\n)\n\nperformance_metrics\n             Metric     Value\nAccuracy   Accuracy 0.8139535\nPrecision Precision 0.8636364\nRecall       Recall 0.7916667\nF1         F1 Score 0.8260870\nggplot(performance_metrics, aes(x = Metric, y = Value)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\", color = \"black\") +\n  labs(x = \"Metric\", y = \"Value\", title = \"Model Performance Metrics\") +\n  theme_minimal()"},{"path":"model-evaluation.html","id":"roc-curve-and-auc-roc","chapter":"8 Model Evaluation","heading":"8.2 ROC Curve and AUC-ROC","text":"ROC Curve plots true positive rate (sensitivity) false positive rate (1 - specificity) various threshold settings. provides visual representation classifier’s performance across different threshold levels. Area ROC Curve (AUC-ROC) quantifies overall performance model distinguishing positive negative classes. higher AUC-ROC value indicates better discrimination performance.","code":"\nlibrary(pROC)\nlibrary(ggplot2)\n\n# Compute predicted probabilities\npredicted_probabilities <- predict(mod_regLogistic_cv, newdata = test_data, type = \"prob\")\n\n# Extract probabilities for the positive class\npositive_probabilities <- predicted_probabilities$\"0\"\n\n# Compute ROC curve and AUC-ROC\nroc_curve <- pROC::roc(test_data$target, positive_probabilities)\nauc_roc <- pROC::auc(roc_curve)\n\n# Plot ROC curve with descriptive axis titles\nggroc(roc_curve, color = \"steelblue\", size = 1) +\n  labs(title = \"Receiver Operating Characteristic (ROC) Curve\",\n       x = \"False Positive Rate (1 - Specificity)\",\n       y = \"True Positive Rate (Sensitivity)\") +\n  theme_minimal()\n\n\n# Print AUC-ROC\ncat(\"AUC-ROC:\", auc_roc)\nAUC-ROC: 0.8486842"},{"path":"model-validation.html","id":"model-validation","chapter":"9 Model Validation","heading":"9 Model Validation","text":"","code":""},{"path":"model-validation.html","id":"cross-validation-techniques","chapter":"9 Model Validation","heading":"9.1 Cross-Validation Techniques","text":"Cross-validation method used evaluate performance generalization ability predictive models. involves partitioning available data multiple subsets, known folds. model trained portion data (training set) evaluated remaining data (validation set). process repeated multiple times, fold serving validation set exactly . Cross-validation provides robust estimate model’s performance compared single train-test split helps identify overfitting.section, explore various cross-validation techniques. Understanding methods essential play significant role subsequent hyperparameter tuning. Cross-validation ensures robust model evaluation assists selecting optimal hyperparameters improved model performance.","code":""},{"path":"model-validation.html","id":"k-fold-cross-validation","chapter":"9 Model Validation","heading":"9.1.1 K-Fold Cross-Validation","text":"K-Fold Cross-Validation divides data K equal-sized folds. model trained K times, time using K-1 folds training set remaining fold validation set.","code":"\n# Example of K-Fold Cross-Validation\nkfcv_ctrl <- caret::trainControl(method = \"cv\", number = 10)"},{"path":"model-validation.html","id":"leave-one-out-cross-validation-loocv","chapter":"9 Model Validation","heading":"9.1.2 Leave-One-Out Cross-Validation (LOOCV)","text":"Leave-One-Cross-Validation involves using single observation validation set remaining observations training set. process repeated observation dataset.","code":"\n# Example of Leave-One-Out Cross-Validation\nloocv_ctrl <- caret::trainControl(method = \"LOOCV\")"},{"path":"model-validation.html","id":"stratified-cross-validation","chapter":"9 Model Validation","heading":"9.1.3 Stratified Cross-Validation","text":"Stratified Cross-Validation ensures fold maintains class distribution original dataset. particularly useful imbalanced datasets.","code":"\n# Example of Stratified Cross-Validation\nstrcv_ctrl <- trainControl(method = \"cv\", \n                     number = 10, \n                     classProbs = TRUE, \n                     summaryFunction = twoClassSummary)"},{"path":"model-validation.html","id":"nested-cross-validation","chapter":"9 Model Validation","heading":"9.1.4 Nested Cross-Validation","text":"Nested Cross-Validation used tune hyperparameters evaluate model performance simultaneously. involves outer loop model evaluation using K-Fold Cross-Validation inner loop hyperparameter tuning.","code":"\n# Example of Nested Cross-Validation\nnestcv_ctrl_outer <- trainControl(method = \"cv\", number = 5)\nnetscv_ctrl_inner <- trainControl(method = \"cv\", number = 3)"},{"path":"model-validation.html","id":"holdout-validation","chapter":"9 Model Validation","heading":"9.2 Holdout Validation","text":"Holdout validation involves splitting dataset two subsets: training set used train model separate validation set used evaluate performance. technique straightforward computationally efficient may suffer high variance validation set small.","code":"library(caret)\n\n# Sample dataset (replace this with your own dataset)\n# data <- train_data\ndata <- data_imputed\n\n# Holdout Validation\nset.seed(123)  # for reproducibility\n\ntrain_indices <- sample(1:nrow(data), 0.8 * nrow(data))  # 80% of data for training\ntrain_data <- data[train_indices, ]\nvalidation_data <- data[-train_indices, ]\n\n# Define your model\n# model <- train(target ~ ., data = train_data, method = \"glm\", family = binomial)\nmodel <- train(target ~ ., data = train_data, method = \"glm\", family = binomial)\n\n# Make predictions on validation data\npredictions <- predict(model, newdata = validation_data)\n\n# Evaluate model performance\n# evaluation_metrics <- confusionMatrix(predictions, validation_data$target)\nevaluation_metrics <- confusionMatrix(predictions, validation_data$target)\nprint(evaluation_metrics)\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  0  1\n         0 16  6\n         1 11 12\n                                          \n               Accuracy : 0.6222          \n                 95% CI : (0.4654, 0.7623)\n    No Information Rate : 0.6             \n    P-Value [Acc > NIR] : 0.4436          \n                                          \n                  Kappa : 0.2478          \n                                          \n Mcnemar's Test P-Value : 0.3320          \n                                          \n            Sensitivity : 0.5926          \n            Specificity : 0.6667          \n         Pos Pred Value : 0.7273          \n         Neg Pred Value : 0.5217          \n             Prevalence : 0.6000          \n         Detection Rate : 0.3556          \n   Detection Prevalence : 0.4889          \n      Balanced Accuracy : 0.6296          \n                                          \n       'Positive' Class : 0               \n                                          "},{"path":"model-validation.html","id":"bootstrapping","chapter":"9 Model Validation","heading":"9.3 Bootstrapping","text":"Bootstrapping resampling technique multiple datasets generated randomly sampling replacement original dataset. dataset used train separate model, aggregate predictions used assess model’s performance. Bootstrapping provides robust estimates model performance can handle small datasets effectively.","code":"library(caret)\n\n# Sample dataset (replace this with your own dataset)\ndata <- data_imputed\n\n# Define your model\nmodel <- train(target ~ ., data = data, method = \"glm\", family = binomial)\n\n# Perform bootstrapping\nset.seed(123)  # for reproducibility\nboot <- createResample(y = data$target, times = 5)\nboot_results <- lapply(boot, function(index) {\n  train_data <- data[index, ]\n  model <- train(target ~ ., data = train_data, method = \"glm\", family = binomial)\n  predict(model, newdata = data[-index, ])\n})\n\n# Aggregate bootstrapped results\nboot_predictions <- do.call(c, boot_results)\n\n# Ensure boot_predictions and data$target have the same length\nmin_length <- min(length(boot_predictions), length(data$target))\nboot_predictions <- boot_predictions[1:min_length]\ndata$target <- data$target[1:min_length]\n\n# Evaluate bootstrapped model performance\nevaluation_metrics <- confusionMatrix(boot_predictions, data$target)\nprint(evaluation_metrics)\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  0  1\n         0 49 52\n         1 74 47\n                                          \n               Accuracy : 0.4324          \n                 95% CI : (0.3663, 0.5004)\n    No Information Rate : 0.5541          \n    P-Value [Acc > NIR] : 0.99989         \n                                          \n                  Kappa : -0.1242         \n                                          \n Mcnemar's Test P-Value : 0.06137         \n                                          \n            Sensitivity : 0.3984          \n            Specificity : 0.4747          \n         Pos Pred Value : 0.4851          \n         Neg Pred Value : 0.3884          \n             Prevalence : 0.5541          \n         Detection Rate : 0.2207          \n   Detection Prevalence : 0.4550          \n      Balanced Accuracy : 0.4366          \n                                          \n       'Positive' Class : 0               \n                                          "},{"path":"hyperparameter-tuning.html","id":"hyperparameter-tuning","chapter":"10 Hyperparameter Tuning","heading":"10 Hyperparameter Tuning","text":"stage, objective refine parameters utilized model fitting maximize performance. concentrate optimizing model’s effectiveness fine-tuning various hyperparameters. parameters, regularization strength tree depth, manually adjusted enhance model’s accuracy. experimentation different values, goal pinpoint optimal combination maximizes performance validation data. pivotal step ensures model excels training data also generalizes effectively new, unseen data.","code":""},{"path":"hyperparameter-tuning.html","id":"demo-tuning-for-a-rlr-model","chapter":"10 Hyperparameter Tuning","heading":"10.1 Demo tuning for a RLR Model","text":"","code":"\n# Set seed for reproducibility\nset.seed(110912)\n\nload(\"data/train_test_data.rda\", verbose = TRUE)## Loading objects:\n##   train_data\n##   test_data\nload(\"models/models.rda\", verbose = TRUE)## Loading objects:\n##   mod_glmnet_adcv\n##   mod_regLogistic_cv\n##   mod_rf_adcv\n##   mod_rf_reptcv\n##   mod_knn_adcv\n##   mod_knn_reptcv\n# Load necessary libraries\nlibrary(caret)## Loading required package: ggplot2## Loading required package: lattice\nlibrary(ggplot2)\n\n# Define the tuning grid\ntuneGrid <- expand.grid(\n  cost = seq(0.001, 1, length.out = 20),  # Define a sequence of cost values\n  loss = \"L2_primal\",  # Specify the loss function\n  epsilon = 0.01  # Set the epsilon value\n)\n\n# Set up cross-validation method\nctrl <- trainControl(\n  method = \"adaptive_cv\",  # Use adaptive cross-validation\n  verboseIter = FALSE  # Print progress during each iteration\n)\n\n# Perform hyperparameter tuning\nmod_regLogistic_cv <- train(\n  target ~ .,  # Define the formula for the model\n  data = train_data,  # Specify the training dataset\n  method = \"regLogistic\",  # Choose the regularized logistic regression method\n  tuneLength = 12,  # Set the number of tuning parameter combinations to try\n  trControl = ctrl,  # Specify the cross-validation method\n  tuneGrid = tuneGrid  # Use the defined tuning grid\n)\n\n# Visualize the model performance\nggplot(mod_regLogistic_cv$results, aes(x = cost, y = Accuracy)) +\n  geom_line(color = \"blue\") +  # Add a line plot\n  geom_point(color = \"black\") +  # Add points for each data point\n  labs(\n    title = \"Accuracy vs. Cost for Regularized Logistic Regression Model (Adaptive CV)\",  # Set the plot title\n    x = \"Cost\",  # Label the x-axis\n    y = \"Accuracy\"  # Label the y-axis\n  ) +\n  theme_bw()  # Apply a black and white theme"},{"path":"model-deployment.html","id":"model-deployment","chapter":"11 Model Deployment","heading":"11 Model Deployment","text":"Deploying trained model regularized logistic regression model others essential predicting binary outcomes microbiome studies. Additionally, implementing monitoring mechanisms crucial track model performance time detect deviations anomalies. ensures continued reliability accuracy microbiome data analysis. Shiny applications serve interfaces machine learning models, providing users convenient platform upload data test model’s performance efficiently.","code":""},{"path":"model-deployment.html","id":"shiny-app-components","chapter":"11 Model Deployment","heading":"11.1 Shiny App components","text":"","code":""},{"path":"model-deployment.html","id":"user-interface-ui","chapter":"11 Model Deployment","heading":"11.1.1 User Interface (UI)","text":"User Interface (UI) component Shiny application serves visual representation app dictates users interact . encompasses various elements like buttons, sliders, text inputs, plots, tables, organized using layout functions fluidPage(), navbarPage(), tabPanel(), etc.Shiny, UI elements created using functions shiny package, serving specific purpose. instance, textInput() creates field users can input text, sliderInput() generates slider selecting numeric values, plotOutput() reserves space displaying plots.UI components typically structured within ui function, acts container assembling app’s visual layout. ’s example UI components defined within ui function:","code":"library(shiny)\n\nload(\"models/models.rda\", verbose = TRUE)\nLoading objects:\n  mod_glmnet_adcv\n  mod_regLogistic_cv\n  mod_rf_adcv\n  mod_rf_reptcv\n  mod_knn_adcv\n  mod_knn_reptcv\nui <- fluidPage(\n  titlePanel(\"My Shiny App\"),  # Adds a title panel at the top of the app\n  sidebarLayout(               # Organizes content into a sidebar and main panel\n    sidebarPanel(              # Defines content for the sidebar\n      textInput(\"text_input\", \"Enter text:\")  # Adds a text input field\n    ),\n    mainPanel(                 # Defines content for the main panel\n      plotOutput(\"plot\")       # Adds a placeholder for displaying plots\n    )\n  )\n)"},{"path":"model-deployment.html","id":"server-for-shiny-app","chapter":"11 Model Deployment","heading":"11.1.2 Server for Shiny App","text":"server component responsible processing user inputs UI generating outputs dynamically.contains logic calculations needed update UI response user actions.server component defined within server function.consists reactive expressions functions specify inputs handled outputs generated.Server functions typically involve observing input values updating reactive values accordingly.example:","code":"\nserver <- function(input, output) {\n  output$plot <- renderPlot({\n    text <- input$text_input\n    hist(rnorm(100, mean = as.numeric(text)), main = \"Histogram\")\n  })\n}"},{"path":"model-deployment.html","id":"shiny-app-deployment","chapter":"11 Model Deployment","heading":"11.2 Shiny App deployment","text":"defined UI server components Shiny application, can proceed deployment process. ’s can next:","code":""},{"path":"model-deployment.html","id":"combine-ui-and-server","chapter":"11 Model Deployment","heading":"11.2.1 Combine UI and Server","text":"Merge UI server components single Shiny application passing shinyApp() function.","code":""},{"path":"model-deployment.html","id":"deploy-the-shiny-app","chapter":"11 Model Deployment","heading":"11.2.2 Deploy the Shiny App","text":"Deploy Shiny application make accessible users. various deployment options available, including:\nHosting app shinyapps.io\nDeploying server\nEmbedding within larger web application\nHosting app shinyapps.ioDeploying serverEmbedding within larger web application","code":""},{"path":"model-deployment.html","id":"test-and-monitor","chapter":"11 Model Deployment","heading":"11.2.3 Test and Monitor","text":"releasing app users, thoroughly test functionality ensure behaves expected.Implement monitoring mechanisms track app’s performance user interactions time.Regularly update maintain app address issues improvements.","code":""},{"path":"model-deployment.html","id":"gather-feedback","chapter":"11 Model Deployment","heading":"11.2.4 Gather Feedback","text":"Encourage users provide feedback app’s usability features.Use feedback make iterative improvements enhancements app.","code":""},{"path":"model-deployment.html","id":"documentation-and-support","chapter":"11 Model Deployment","heading":"11.2.5 Documentation and Support","text":"Provide clear documentation instructions use app.Offer support channels users seek assistance report issues.","code":""},{"path":"model-deployment.html","id":"continuous-improvement","chapter":"11 Model Deployment","heading":"11.2.6 Continuous Improvement","text":"Continuously iterate app based user feedback evolving requirements.Stay updated Shiny R developments incorporate new features best practices.following steps, can successfully deploy Shiny application ensure continued success usefulness users.","code":""},{"path":"model-deployment.html","id":"extended-user-interface","chapter":"11 Model Deployment","heading":"11.3 Extended user interface","text":"","code":"\nlibrary(shiny)\nlibrary(shinydashboard)\nlibrary(shinythemes)\n\n# UI chunk\nui <- shinyUI(dashboardPage(\n  skin = \"black\",\n  dashboardHeader(\n    title = em(\"Shiny Machine Learning App\", style = \"text-align:center;color:#006600;font-size:100%\"),\n    titleWidth = 800\n  ),\n  dashboardSidebar(\n    width = 250,\n    sidebarMenu(\n      br(),\n      menuItem(em(\"Upload Test Data\", style = \"font-size:120%\"), icon = icon(\"upload\"), tabName = \"data\"),\n      menuItem(em(\"Download Predictions\", style = \"font-size:120%\"), icon = icon(\"download\"), tabName = \"download\")\n    )\n  ),\n  dashboardBody(\n    tabItems(\n      tabItem(\n        tabName = \"data\",\n        br(),\n        tags$h4(\n          \"This shiny app allows you to upload your data, do prediction, and download results.\",\n          em(\"This example demonstrates a Regularized Logistic Regression.\"),\n          \"You can predict whether an individual is healthy or unhealthy.\",\n          \"By evaluating the results, you can make a decision if the model predicts correctly or poorly.\",\n          style = \"font-size:150%\"\n        ),\n        br(),\n        tags$h4(\n          \"Start by uploading test data, preferably in \",\n          code(\"csv format\"),\n          style = \"font-size:150%\"\n        ),\n        tags$h4(\n          \"Then, go to the \",\n          tags$span(\"Download Predictions\", style = \"color:red\"),\n          \" section in the sidebar to download the predictions.\",\n          style = \"font-size:150%\"\n        ),\n        br(),\n        br(),\n        br(),\n        column(\n          width = 4,\n          fileInput(\n            'file1',\n            em('Upload test data in csv format', style = \"text-align:center;color:blue;font-size:150%\"),\n            multiple = FALSE,\n            accept = c('.csv')\n          ),\n          uiOutput(\"sample_input_data_heading\"),\n          tableOutput(\"sample_input_data\"),\n          br(),\n          br()\n        )\n      ),\n      tabItem(\n        tabName = \"download\",\n        fluidRow(\n          br(),\n          br(),\n          br(),\n          br(),\n          column(\n            width = 8,\n            tags$h4(\n              \"After you upload a test dataset, you can download the predictions in csv format by clicking the button below.\",\n              style = \"font-size:200%\"\n            ),\n            br(),\n            br()\n          )\n        ),\n        fluidRow(\n          column(\n            width = 7,\n            downloadButton(\n              \"downloadData\",\n              em('Download Predictions', style = \"text-align:center;color:blue;font-size:150%\")\n            ),\n            plotOutput('plot_predictions')\n          ),\n          column(\n            width = 4,\n            uiOutput(\"sample_prediction_heading\"),\n            tableOutput(\"sample_predictions\")\n          )\n        )\n      )\n    )\n  )\n))"},{"path":"model-deployment.html","id":"extended-server","chapter":"11 Model Deployment","heading":"11.4 Extended server","text":"","code":"\nload(\"models/models.rda\", verbose = TRUE)\nLoading objects:\n  mod_glmnet_adcv\n  mod_regLogistic_cv\n  mod_rf_adcv\n  mod_rf_reptcv\n  mod_knn_adcv\n  mod_knn_reptcv\n\n# Server chunk\nserver <- function(input, output) {\n  \n  # Set maximum web request size to 80MB\n  options(shiny.maxRequestSize = 800 * 1024^2) \n  \n  # Render UI elements for sample input data heading and table\n  output$sample_input_data_heading <- renderUI({\n    inFile <- input$file1\n    if (is.null(inFile)) {\n      return(NULL)\n    } else {\n      tags$h4('Sample Input Data')\n    }\n  })\n  \n  output$sample_input_data <- renderTable({\n    inFile <- input$file1\n    if (is.null(inFile)) {\n      return(NULL)\n    } else {\n      input_data <- readr::read_csv(input$file1$datapath, col_names = TRUE)\n      colnames(input_data) <- c(\"Label\", \"Test1\", \"Test2\")\n      input_data$Label <- factor(input_data$Label, labels = c(\"African American\", \"African\"))\n      head(input_data)\n    }\n  })\n  \n  # Perform predictions on uploaded data\n  predictions <- reactive({\n    inFile <- input$file1\n    if (is.null(inFile)) {\n      return(NULL)\n    } else {\n      withProgress(message = 'Predictions in progress. Please wait ...', {\n        input_data <- readr::read_csv(input$file1$datapath, col_names = TRUE)\n        colnames(input_data) <- c(\"Label\", \"Test1\", \"Test2\")\n        input_data$Label <- factor(input_data$Label, labels = c(\"African American\", \"African\"))\n        mapped <- feat_map(input_data)\n        df_final <- cbind(input_data, mapped)\n        prediction <- predict(mod_regLogistic_cv, df_final)\n        input_data_with_prediction <- cbind(input_data, prediction)\n        input_data_with_prediction\n      })\n    }\n  })\n  \n  # Render UI elements for sample predictions heading and table\n  output$sample_prediction_heading <- renderUI({\n    inFile <- input$file1\n    if (is.null(inFile)) {\n      return(NULL)\n    } else {\n      tags$h4('Input with Predictions')\n    }\n  })\n  \n  output$sample_predictions <- renderTable({\n    pred <- predictions()\n    head(pred)\n  })\n  \n  # Render plot of predictions\n  output$plot_predictions <- renderPlot({\n    pred <- predictions()\n    cols <- c(\"African American\" = \"green4\", \"African\" = \"red\")\n    pred %>% \n      ggplot(aes(x = Test1, y = Test2, color = factor(prediction))) + \n      geom_point(size = 4, shape = 19, alpha = 0.6) +\n      scale_colour_manual(values = cols, \n                          labels = c(\"African American\", \"African\"), \n                          name = \"Variable\") +\n      theme_bw()\n  })\n  \n  # Downloadable CSV of predictions\n  output$downloadData <- downloadHandler(\n    filename = function() {\n      paste(\"input_data_with_predictions\", \".csv\", sep = \"\")\n    },\n    content = function(file) {\n      write.csv(predictions(), file, row.names = FALSE)\n    }\n  )\n  \n}"},{"path":"model-deployment.html","id":"calling-shiny-app","chapter":"11 Model Deployment","heading":"11.5 Calling Shiny App","text":"Using shinyApp functionUsing shinyApp functionApp directory: application resides specific app_directory, launch :App directory: application resides specific app_directory, launch :Shiny app object: ’ve created Shiny app object console calling shinyApp(), can pass app object runApp() like :","code":"\n# Deployment chunk\nshinyApp(ui = ui, server = server)runApp(\"app_directory\")\n  # Create app object (assume ui and server are defined)\napp <- shinyApp(ui, server)\n\nrunApp(app)app\n"},{"path":"model-deployment.html","id":"example-app-with-qualitative-data-using-burro-package","chapter":"11 Model Deployment","heading":"11.6 Example APP with Qualitative data using Burro package","text":"\nlibrary(burro)\n\nlibrary(NHANES)\n\ndata(NHANES)\n\nNHANES %>% mutate(gr = 1) %>% ggplot(aes_string(x =\n“AgeDecade”, fill = “AgeDecade”)) + geom_bar(aes(y = ..count..), color =\n“black”) + viridis::scale_fill_viridis(discrete = TRUE, option =\n“magma”) + geom_text(aes(group = gr, label = scales::percent(..prop..),\ny = ..count..), stat = “count”, vjust = -0.5) + theme(axis.text.x =\nelement_text(angle = 90), legend.position = “none”)\n\ndata_dict <-\nreadr::read_csv(system.file(“nhanes/data_dictionary.csv”,\npackage=“burro”))\n\noutcome <- c(“Depressed”)\n\nexplore_data(dataset=NHANES, data_dictionary=data_dict,\noutcome_var=outcome)\n","code":""},{"path":"modeling-ideas.html","id":"modeling-ideas","chapter":"A Modeling Ideas","heading":"A Modeling Ideas","text":"case study, explore performance predictive model developed assess likelihood cancer patients based various medical records. model incorporated patient demographics, medical history, vital signs, diagnostic test results. tested held-dataset, demonstrated exceptional accuracy evaluation.However, upon deployment predict cancer likelihood new patients, model exhibited significant discrepancies performance. discrepancy led investigation uncover potential causes observed inconsistency.","code":""},{"path":"modeling-ideas.html","id":"identifying-the-issue","chapter":"A Modeling Ideas","heading":"A.1 Identifying the Issue","text":"Upon closer examination, became evident model’s poor performance new patients attributed information leakage. Specifically, one feature model inadvertently exposed sensitive information, influenced predictions. form information leakage compromised model’s ability generalize unseen data effectively.","code":""},{"path":"modeling-ideas.html","id":"implications","chapter":"A Modeling Ideas","heading":"A.2 Implications","text":"Information leakage poses serious implications predictive model’s reliability fairness. inadvertently incorporating sensitive information, patient-specific details external factors related prediction task, model’s performance new data can compromised. can lead inaccurate predictions potentially harmful outcomes relied upon clinical decision-making.","code":""},{"path":"modeling-ideas.html","id":"recommendations","chapter":"A Modeling Ideas","heading":"A.3 Recommendations","text":"Conducting thorough feature selection validation processes imperative address information leakage ensure model’s robustness generalizability. involves identifying removing features may inadvertently expose sensitive information introduce bias model. Additionally, implementing rigorous data preprocessing techniques adhering best practices model development can help mitigate risk information leakage enhance reliability predictive models.prioritizing transparency, fairness, ethical considerations throughout model development process, can mitigate risks associated information leakage build accurate trustworthy predictive models.","code":""},{"path":"modeling-ideas.html","id":"some-effective-ml-guidelines","chapter":"A Modeling Ideas","heading":"A.4 Some Effective ML Guidelines","text":"Keep first model simple.Focus ensuring data pipeline correctness.Use simple, observable metric training & evaluation.monitor input featuresTreat model configuration code: review , check inWrite results experiments, especially “failures”","code":""},{"path":"using-ml-helper-function.html","id":"using-ml-helper-function","chapter":"B Using ML helper function","heading":"B Using ML helper function","text":"know different hyperparameter options dafault values different modeling approaches","code":"load(\"data/ml_n_composite_object.rda\", verbose = TRUE)\nLoading objects:\n  composite\n  metabo_composite\n  ml_genus_dsestate\n  ps_df\n  ml_genus_enttype\n  ml_genus_nationality\n  ml_genus_bmilibrary(mikropml)\n\nget_hyperparams_list(ml_genus_nationality, \"glmnet\")\n$lambda\n[1] 1e-04 1e-03 1e-02 1e-01 1e+00 1e+01\n\n$alpha\n[1] 0\nget_hyperparams_list(ml_genus_nationality, \"rf\")\n$mtry\n[1]  6 12 24\nget_hyperparams_list(ml_genus_nationality, \"svmRadial\")\n$C\n[1] 1e-03 1e-02 1e-01 1e+00 1e+01 1e+02\n\n$sigma\n[1] 1e-06 1e-05 1e-04 1e-03 1e-02 1e-01\nget_hyperparams_list(ml_genus_nationality, \"rpart2\") # Decision tree\n$maxdepth\n[1]  1  2  4  8 16 30\nget_hyperparams_list(ml_genus_nationality, \"xgbTree\") # XGBoost\n$nrounds\n[1] 100\n\n$gamma\n[1] 0\n\n$eta\n[1] 0.001 0.010 0.100 1.000\n\n$max_depth\n[1]  1  2  4  8 16 30\n\n$colsample_bytree\n[1] 0.8\n\n$min_child_weight\n[1] 1\n\n$subsample\n[1] 0.4 0.5 0.6 0.7"},{"path":"imap-github-repos.html","id":"imap-github-repos","chapter":"C IMAP GitHub Repos","heading":"C IMAP GitHub Repos","text":"","code":""},{"path":"session-information.html","id":"session-information","chapter":"D Session Information","heading":"D Session Information","text":"Reproducibility relies ability precisely recreate working environment, session information serves vital reference achieve consistency. record details R environment, package versions, system settings computing environment time analysis.","code":"\nlibrary(sessioninfo)\n\n# Get session info\ninfo <- capture.output(print(session_info()))\n\n# Define patterns to exclude\nexclude_patterns <- c(\"/Users/.*\", \"Africa/Dar_es_Salaam\") # This line is location-dependent\n\n# Exclude lines containing specific information\ninfo_filtered <- info[!grepl(paste(exclude_patterns, collapse = \"|\"), info)]\n\n# Save the filtered session info to a text file in the root directory without line numbers\ncat(info_filtered, file = \"session_info.txt\", sep = \"\\n\")"},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
