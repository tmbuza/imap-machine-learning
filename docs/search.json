[{"path":"index.html","id":"machine-learning","chapter":"IMAP-Part 10: Predictive Modeling Using Microbiome Data","heading":"IMAP-Part 10: Predictive Modeling Using Microbiome Data","text":"","code":""},{"path":"index.html","id":"welcome-to-imap-chapter-10-machine-learning-guide-for-microbiome-data","chapter":"IMAP-Part 10: Predictive Modeling Using Microbiome Data","heading":"Welcome to IMAP chapter 10: Machine Learning Guide for Microbiome Data","text":"Welcome exploration machine learning’s pivotal role deciphering microbiome data. realm biomedical research, understanding microbial communities interactions host organisms crucial unraveling complexities health disease.Machine learning techniques offer powerful tools analyze vast amounts genetic, metagenomic, metadata generated microbiome studies. leveraging computational algorithms, researchers can extract meaningful patterns, predict microbial behavior, uncover associations various health conditions.Throughout guide, ’ll delve application machine learning microbiome research, exploring computational techniques revolutionizing understanding microbial ecosystems. Together, ’ll uncover insights intricate relationships microbial communities implications human health environmental sustainability.Join us journey navigate fascinating intersection machine learning microbiome research, discover transformative potential computational techniques advancing biomedical science.","code":""},{"path":"key-components-of-microbiome-machine-learning.html","id":"key-components-of-microbiome-machine-learning","chapter":"1 Key Components of Microbiome Machine Learning","heading":"1 Key Components of Microbiome Machine Learning","text":"Machine learning microbiome research encompasses several key components, playing vital role extracting insights complex microbial data:Feature Engineering: core microbiome analysis lies extraction relevant features diverse data sources, including microbial abundance, diversity metrics, host metadata. Effective feature engineering lays groundwork subsequent analysis model development.Feature Engineering: core microbiome analysis lies extraction relevant features diverse data sources, including microbial abundance, diversity metrics, host metadata. Effective feature engineering lays groundwork subsequent analysis model development.Classification Prediction: Machine learning models play crucial role classifying samples distinct groups (e.g., healthy vs. diseased) predicting clinical outcomes based microbiome profiles. Algorithms Random Forests Neural Networks enable accurate predictions, aiding disease diagnosis prognosis.Classification Prediction: Machine learning models play crucial role classifying samples distinct groups (e.g., healthy vs. diseased) predicting clinical outcomes based microbiome profiles. Algorithms Random Forests Neural Networks enable accurate predictions, aiding disease diagnosis prognosis.Community Profiling: Unsupervised learning techniques, clustering ordination, unveil microbial community structures similarities. characterizing microbial ecosystems, community profiling enhances understanding microbial diversity ecological dynamics.Community Profiling: Unsupervised learning techniques, clustering ordination, unveil microbial community structures similarities. characterizing microbial ecosystems, community profiling enhances understanding microbial diversity ecological dynamics.Microbial Interaction Networks: Graph-based methods uncover intricate co-occurrence patterns identify keystone species within microbial communities. Understanding microbial interactions provides insights ecosystem stability, resilience, functional diversity.Microbial Interaction Networks: Graph-based methods uncover intricate co-occurrence patterns identify keystone species within microbial communities. Understanding microbial interactions provides insights ecosystem stability, resilience, functional diversity.Ecological Modeling: Machine learning algorithms model microbial ecosystem dynamics, capturing complex interactions microbial taxa environment. Ecological modeling elucidates succession patterns, responses environmental changes, ecosystem-level processes.Ecological Modeling: Machine learning algorithms model microbial ecosystem dynamics, capturing complex interactions microbial taxa environment. Ecological modeling elucidates succession patterns, responses environmental changes, ecosystem-level processes.Biomarker Discovery: Feature selection techniques identify microbial taxa pathways serving biomarkers specific health conditions environmental factors. Biomarker discovery facilitates early disease detection, personalized treatment strategies, environmental monitoring.Biomarker Discovery: Feature selection techniques identify microbial taxa pathways serving biomarkers specific health conditions environmental factors. Biomarker discovery facilitates early disease detection, personalized treatment strategies, environmental monitoring.Personalized Medicine:** Machine learning enables development personalized interventions based individual microbiome profiles. integrating microbiome data clinical information, personalized medicine offers targeted therapies preventive strategies tailored individual’s unique microbial composition.Personalized Medicine:** Machine learning enables development personalized interventions based individual microbiome profiles. integrating microbiome data clinical information, personalized medicine offers targeted therapies preventive strategies tailored individual’s unique microbial composition.Together, key components form foundation microbiome machine learning, driving advancements biomedical research, personalized healthcare, environmental sustainability.","code":""},{"path":"ml-framework_R.html","id":"ml-framework_R","chapter":"2 Machine Learning Framework in R: From Data Acquisition to Model Deployment","heading":"2 Machine Learning Framework in R: From Data Acquisition to Model Deployment","text":"Discover comprehensive framework leveraging machine learning R analyze microbiome data. showcase framework using publicly available data microbiome metagenomics analysis, accessible R packages NCBI. capitalizing resources, demonstrate application advanced analytical techniques. initiative underscores value open-access data also highlights broader implications precision medicine personalized healthcare.","code":""},{"path":"ml-framework_R.html","id":"data-acquisition-from-ncbi","chapter":"2 Machine Learning Framework in R: From Data Acquisition to Model Deployment","heading":"2.1 Data Acquisition from NCBI","text":"Data NCBI project PRJEB13870, titled “Gut microbiota dysbiosis contributes development hypertension” Zhao et al., 2017.Data dietswap dataset microbiome package, offering insights impact dietary interventions gut microbiota composition","code":""},{"path":"ml-framework_R.html","id":"model-development-pipeline","chapter":"2 Machine Learning Framework in R: From Data Acquisition to Model Deployment","heading":"2.2 Model Development Pipeline","text":"","code":""},{"path":"ml-framework_R.html","id":"data-cleaning-and-tidying","chapter":"2 Machine Learning Framework in R: From Data Acquisition to Model Deployment","heading":"2.2.1 Data Cleaning and Tidying","text":"Feature OTU tableTaxonomy tableMetadataMetabolic pathwaysOther experimental data…","code":""},{"path":"ml-framework_R.html","id":"exploratory-data-analysis","chapter":"2 Machine Learning Framework in R: From Data Acquisition to Model Deployment","heading":"2.2.2 Exploratory Data Analysis","text":"Diversity analysisTaxonomic profilingDifferential abundance analysisFunctional profiling","code":""},{"path":"ml-framework_R.html","id":"feature-engineering","chapter":"2 Machine Learning Framework in R: From Data Acquisition to Model Deployment","heading":"2.2.3 Feature Engineering","text":"Dimensionality reduction techniques (e.g., PCA, t-SNE)Feature selection methods (e.g., Boruta, LASSO)","code":""},{"path":"ml-framework_R.html","id":"model-development","chapter":"2 Machine Learning Framework in R: From Data Acquisition to Model Deployment","heading":"2.2.4 Model Development","text":"Selection appropriate machine learning algorithms (e.g., Random Forest, Support Vector Machines)Hyperparameter tuning using cross-validationModel evaluation metrics (e.g., accuracy, precision, recall, F1-score)","code":""},{"path":"ml-framework_R.html","id":"model-interpretation","chapter":"2 Machine Learning Framework in R: From Data Acquisition to Model Deployment","heading":"2.2.5 Model Interpretation","text":"Feature importance analysisVisualization model predictions (e.g., ROC curves, confusion matrices)","code":""},{"path":"ml-framework_R.html","id":"integration-with-biological-knowledge","chapter":"2 Machine Learning Framework in R: From Data Acquisition to Model Deployment","heading":"2.2.6 Integration with Biological Knowledge","text":"Interpretation model results context biological mechanismsIdentification potential biomarkers therapeutic targets","code":""},{"path":"ml-framework_R.html","id":"deployment-and-validation","chapter":"2 Machine Learning Framework in R: From Data Acquisition to Model Deployment","heading":"2.2.7 Deployment and Validation","text":"Application trained models new datasetsValidation model performance independent cohorts","code":""},{"path":"ml-framework_R.html","id":"model-framework-graphically","chapter":"2 Machine Learning Framework in R: From Data Acquisition to Model Deployment","heading":"2.3 Model Framework Graphically","text":", present visualization primary stages entailed constructing assessing machine learning model microbiome analysis.","code":""},{"path":"ml-framework_R.html","id":"data-preprocessing","chapter":"2 Machine Learning Framework in R: From Data Acquisition to Model Deployment","heading":"2.3.1 Data Preprocessing","text":"","code":"\nlibrary(DiagrammeR)\nlibrary(DiagrammeRsvg)\n\nmermaid(\"graph TD\n\nsubgraph A\n\nA[Data Cleaning and Transformation] --> B[Exploratory Analysis]\nB --> C[Feature Selection]\nC --> D[Feature Balancing]\nD --> E[Multi-Model Testing]\nend\n\n\", height = 800, width = 1000)"},{"path":"ml-framework_R.html","id":"model-development-1","chapter":"2 Machine Learning Framework in R: From Data Acquisition to Model Deployment","heading":"2.3.2 Model Development","text":"","code":"\nlibrary(DiagrammeR)\nlibrary(DiagrammeRsvg)\n\nmermaid(\"graph TD\n\nsubgraph B\n\nE[Machine Learning Model Development] --> F[Model Selection]\nF --> G[Parameters Tuning]\nG --> H[Parameter Cross-Validation]\nH --> I[Model Training]\nI --> J[Model Testing]\nend\n\n\", height = 800, width = 1000)"},{"path":"ml-framework_R.html","id":"model-evaluation-and-interpretation","chapter":"2 Machine Learning Framework in R: From Data Acquisition to Model Deployment","heading":"2.3.3 Model Evaluation and Interpretation","text":"","code":"\nlibrary(DiagrammeR)\nlibrary(DiagrammeRsvg)\n\nmermaid(\"graph TD\n\nsubgraph C\n\nJ[Model Evaluation and Interpretation] --> K[Performance Metrics]\nK --> L[Model Comparison]\nL --> M[Interpretation and Insights]\nM --> N[Deployment]\nN --> O[Validation]\nend\n\n\", height = 800, width = 1000)"},{"path":"ml-framework_R.html","id":"performance-metrics","chapter":"2 Machine Learning Framework in R: From Data Acquisition to Model Deployment","heading":"2.3.4 Performance metrics","text":"","code":"\nlibrary(DiagrammeR)\nlibrary(DiagrammeRsvg)\n\nmermaid(\"graph LR\n\nsubgraph D\n\nK{Model Evaluation} --> P[ROC: Receiver Operating Characteristic Curve]\nK --> Q[Precision Recall Curve]\nK --> R[F1 Score]\nK --> S[Confusion Matrix]\nK --> T[Accuracy]\nK --> U[Recall]\nK --> V[Precision]\nend\n\n\", height = 800, width = 1000)"},{"path":"machine-learning-prototypes-streamlining-microbiome-model-development-and-deployment.html","id":"machine-learning-prototypes-streamlining-microbiome-model-development-and-deployment","chapter":"3 Machine Learning Prototypes: Streamlining Microbiome Model Development and Deployment","heading":"3 Machine Learning Prototypes: Streamlining Microbiome Model Development and Deployment","text":"Machine Learning Prototypes (MLPs) serve foundational frameworks accelerating enhancing machine learning endeavors within context microbiome research. robust solutions offer streamlined approaches developing, deploying, monitoring machine learning models tailored specifically microbiome data analysis.","code":""},{"path":"machine-learning-prototypes-streamlining-microbiome-model-development-and-deployment.html","id":"key-features-of-ml-prototype","chapter":"3 Machine Learning Prototypes: Streamlining Microbiome Model Development and Deployment","heading":"3.1 Key Features of ML Prototype","text":"essential attributes characteristics MLPs:Robust Open-Source: MLPs robust, open-source solutions designed accelerate development deployment machine learning models.Robust Open-Source: MLPs robust, open-source solutions designed accelerate development deployment machine learning models.Comprehensive Frameworks: Fully developed MLPs empower Data Scientists providing comprehensive frameworks seamlessly build, deploy, monitor ML models.Comprehensive Frameworks: Fully developed MLPs empower Data Scientists providing comprehensive frameworks seamlessly build, deploy, monitor ML models.Tailored Common Use Cases: MLPs meticulously crafted around common industry use cases, Churn Prediction Monitoring Anomaly Detection, ensuring relevance applicability across diverse domains.Tailored Common Use Cases: MLPs meticulously crafted around common industry use cases, Churn Prediction Monitoring Anomaly Detection, ensuring relevance applicability across diverse domains.Built According Best Practices: MLPs developed according best practices, undergoing rigorous review testing guarantee reliability performance.Built According Best Practices: MLPs developed according best practices, undergoing rigorous review testing guarantee reliability performance.Reproducibility: MLPs designed reproducible, offering flexibility retrain models develop customized applications tailored specific needs.Reproducibility: MLPs designed reproducible, offering flexibility retrain models develop customized applications tailored specific needs.Advantageous Head Start: MLPs offer significant advantage providing head start machine learning development process.Advantageous Head Start: MLPs offer significant advantage providing head start machine learning development process.","code":""},{"path":"exploratory-data-analysis-eda.html","id":"exploratory-data-analysis-eda","chapter":"4 Exploratory Data Analysis (EDA)","heading":"4 Exploratory Data Analysis (EDA)","text":"machine learning start exploring data understand structure, patterns, relationships within data. involves visualizing distributions, correlations, relevant statistics gain insights dataset.","code":""},{"path":"exploratory-data-analysis-eda.html","id":"preprocessing-metagenomics-data","chapter":"4 Exploratory Data Analysis (EDA)","heading":"4.1 Preprocessing Metagenomics data","text":"Source: PRJEB13870. project titled “Gut microbiota dysbiosis contributes development hypertension” serves ideal resource metagenomics dataset. dataset offers valuable insights association gut microbiota composition hypertension development, critical area research within fields microbiology cardiovascular health.","code":"\n# Load necessary libraries with suppressed startup messages\nlibrary(tidyverse, suppressPackageStartupMessages())\nlibrary(broom)\nlibrary(ggtext)\nlibrary(data.table)\n\n# Set seed for reproducibility\nset.seed(2022)\n\n# Read and process the OTU table data\notutable <- read_csv(\"data/HypertensionProject.csv\", show_col_types = FALSE) %>%\n  dplyr::select(1, Prevotella:ncol(.)) %>%\n  data.table::transpose(keep.names = \"taxonomy\", make.names = \"SampleID\") %>%\n  pivot_longer(-taxonomy, names_to=\"sample_id\", values_to=\"rel_abund\") %>%\n  relocate(sample_id)\n\n# Read and process the metabolites data\nmetabolites <- read_csv(\"data/HypertensionProjectMetabolites.csv\", show_col_types = FALSE) %>%\n  select(c(1, 5:ncol(.))) %>%\n  data.table::transpose(keep.names = \"metabopwy\", make.names = \"SampleID\") %>%\n  pivot_longer(-metabopwy, names_to=\"sample_id\", values_to=\"value\") %>%\n  group_by(sample_id) %>% \n  mutate(rel_abund = value/sum(value)) %>% \n  ungroup() %>% \n  dplyr::select(-value) %>% \n  relocate(sample_id)\n\n# Read and process the taxonomy data\ntaxonomy <- read_tsv(\"data/mo_demodata/baxter.cons.taxonomy\", show_col_types = FALSE) %>%\n  rename_all(tolower) %>%\n  dplyr::select(otu, taxonomy) %>%\n  mutate(taxonomy = str_replace_all(taxonomy, \"\\\\(\\\\d+\\\\)\", \"\"),\n         taxonomy = str_replace(taxonomy, \";unclassified\", \"_unclassified\"),\n         taxonomy = str_replace_all(taxonomy, \";unclassified\", \"\"),\n         taxonomy = str_replace_all(taxonomy, \";$\", \"\"),\n         taxonomy = str_replace_all(taxonomy, \".*;\", \"\"))\n\n# Read and process the metadata\nmetadata <- read_csv(\"data/HypertensionProject.csv\", show_col_types = FALSE) %>%\n  dplyr::select(c(1:3)) %>%\n  mutate(hyper = Disease_State == \"HTN\" | Disease_State == \"pHTN\",\n         control = Disease_State == \"healthy\") %>%\n  rename(sample_id = SampleID)"},{"path":"exploratory-data-analysis-eda.html","id":"metagenomics-data-joining","chapter":"4 Exploratory Data Analysis (EDA)","heading":"4.2 Metagenomics data joining","text":"","code":""},{"path":"exploratory-data-analysis-eda.html","id":"join-metadata-with-metagenomics-otu-table","chapter":"4 Exploratory Data Analysis (EDA)","heading":"4.2.1 Join metadata with metagenomics OTU table","text":"","code":"# Join metadata with OTU table to create composite dataset\ncomposite <- inner_join(metadata, otutable, by=\"sample_id\")\nhead(composite)\n# A tibble: 6 × 7\n  sample_id  Disease_State Enterotype   hyper control taxonomy         rel_abund\n  <chr>      <chr>         <chr>        <lgl> <lgl>   <chr>                <dbl>\n1 ERR1398068 HTN           Enterotype_1 TRUE  FALSE   Prevotella         5.53e-1\n2 ERR1398068 HTN           Enterotype_1 TRUE  FALSE   Faecalibacterium   1.70e-2\n3 ERR1398068 HTN           Enterotype_1 TRUE  FALSE   Klebsiella         2.99e-6\n4 ERR1398068 HTN           Enterotype_1 TRUE  FALSE   Roseburia          7.47e-3\n5 ERR1398068 HTN           Enterotype_1 TRUE  FALSE   Bifidobacterium    1.92e-3\n6 ERR1398068 HTN           Enterotype_1 TRUE  FALSE   Enterobacter       8.52e-7"},{"path":"exploratory-data-analysis-eda.html","id":"join-metadata-with-metabolites-data","chapter":"4 Exploratory Data Analysis (EDA)","heading":"4.2.2 Join metadata with metabolites data","text":"","code":"# Join metadata with metabolites data to create composite metabolites dataset\nmetabo_composite <- inner_join(metadata, metabolites, by=\"sample_id\")\nhead(metabo_composite)\n# A tibble: 6 × 7\n  sample_id  Disease_State Enterotype   hyper control metabopwy        rel_abund\n  <chr>      <chr>         <chr>        <lgl> <lgl>   <chr>                <dbl>\n1 ERR1398068 HTN           Enterotype_1 TRUE  FALSE   LPS_biosynthesis 0.00962  \n2 ERR1398068 HTN           Enterotype_1 TRUE  FALSE   LPS_transport    0.0000221\n3 ERR1398068 HTN           Enterotype_1 TRUE  FALSE   PTS              0.203    \n4 ERR1398068 HTN           Enterotype_1 TRUE  FALSE   Secretion_Syste… 0.0000221\n5 ERR1398068 HTN           Enterotype_1 TRUE  FALSE   Secretion_Syste… 0        \n6 ERR1398068 HTN           Enterotype_1 TRUE  FALSE   Secretion_Syste… 0.000375 "},{"path":"exploratory-data-analysis-eda.html","id":"preprocessing-microbiome-data","chapter":"4 Exploratory Data Analysis (EDA)","heading":"4.3 Preprocessing microbiome data","text":"outline steps involved processing integrating microbiome (16S rRNA) OTU table, taxonomy data, metadata, please refer imap-data-preparation. primary dataset sourced publicly available Dietswap dataset, retrieved microbiome package. dataset preprocessed integrated long-form dataframe format.","code":"load(\"data/phyloseq_raw_rel_psextra_df_objects.rda\", verbose = TRUE)\nLoading objects:\n  ps_raw\n  ps_rel\n  psextra_raw\n  psextra_rel\n  ps_df\n\ncat(\"We will use object ps_df, here is the ps_df structure\\n\")\nWe will use object ps_df, here is the ps_df structure\nhead(ps_df[, c(1, 4, 9, 11, 12, 13)])\n# A tibble: 6 × 6\n  sample_id  nationality bmi        rel_abund level  taxon                      \n  <chr>      <fct>       <fct>          <dbl> <chr>  <chr>                      \n1 Sample-208 AFR         overweight     0.617 phylum *Bacteroidetes*            \n2 Sample-208 AFR         overweight     0.617 family *Bacteroidetes*            \n3 Sample-208 AFR         overweight     0.617 genus  *Prevotella melaninogenica*\n4 Sample-208 AFR         overweight     0.617 otu    *Prevotella melaninogenica*\n5 Sample-212 AFR         obese          0.702 phylum *Bacteroidetes*            \n6 Sample-212 AFR         obese          0.702 family *Bacteroidetes*            "},{"path":"feature-engineering-1.html","id":"feature-engineering-1","chapter":"5 Feature Engineering","heading":"5 Feature Engineering","text":"Feature engineering crucial step machine learning pipeline raw data transformed format enhances performance predictive models. process involves creating new features, selecting relevant features, transforming existing features improve model’s ability capture patterns make accurate predictions.common techniques used feature engineering include:Feature Creation: Generating new features existing ones, extracting information text, dates, categorical variables, creating interaction terms variables.Feature Selection: Identifying relevant features contribute predictive power model reducing dimensionality computational complexity.Feature Transformation: Applying transformations features make data suitable modeling, scaling numeric features, encoding categorical variables, handling missing values.performing effective feature engineering, can improve performance, interpretability, robustness machine learning models, ultimately leading better predictions insights data.","code":""},{"path":"feature-engineering-1.html","id":"processing-data-for-machine-learning","chapter":"5 Feature Engineering","heading":"5.1 Processing data for machine learning","text":"section outlines preprocessing steps involved preparing data subsets tailored machine learning analysis. code segments transform raw data structured formats suitable predictive modeling. Specifically, subsets created encompass various combinations taxonomic metabolic features alongside binary labels representing selected features. subset undergoes specific preprocessing steps, including data selection, transformation, encoding, ensure compatibility machine learning algorithms.\nNote users:\n\nencounter issues data processing pivot_wider()\nreturns values <list>, may due multiple values \ncombination identifiers (e.g., sample ID feature). \ncases, consider aggregating values using group_by() summarise()\npivoting.\n\nExample:\n\nps_df %>% select(sample_id, taxon, nationality, rel_abund, bmi)\n%>% mutate(taxon = str_replace_all(taxon, “*“,”“)) %>%\ngroup_by(sample_id, taxon, nationality, bmi) %>% summarise(rel_abund\n= mean(rel_abund), .groups =”drop”) %>% pivot_wider(names_from =\ntaxon, values_from = rel_abund) %>% mutate(nationality =\nif_else(nationality == “AAM”, “0”, “1”)) %>% mutate(bmi = if_else(bmi\n== “overweight” | bmi == “obese” , “0”, “1”)) %>%\nselect(-c(sample_id, bmi))\n\nensures rel_abund values properly aggregated \npivoting.\n","code":"\nlibrary(dplyr)\nlibrary(tidyr)\n\n# Subset for machine learning analysis: Taxonomic genus features with disease states\n\nml_genus_dsestate <- composite %>%\n  select(sample_id, taxonomy, enttype = Enterotype, rel_abund, dsestate = Disease_State) %>%\n  pivot_wider(names_from=taxonomy, values_from = rel_abund) %>%\n  select(-sample_id) %>%\n  mutate(enttype = if_else(enttype == \"Enterotype_1\", \"0\", \"1\")) %>%\n  mutate(dsestate = if_else(dsestate == \"pHTN\" | dsestate == \"HTN\" , \"0\", \"1\")) %>%\n  select(-enttype) %>%\n  select(dsestate, everything())\n\n# Subset for machine learning analysis: Taxonomic genus features with enterotypes\nml_genus_enttype <- composite %>%\n  select(sample_id, taxonomy, enttype = Enterotype, rel_abund, dsestate = Disease_State) %>%\n  pivot_wider(names_from=taxonomy, values_from = rel_abund) %>%\n  select(-sample_id) %>%\n  mutate(enttype = if_else(enttype == \"Enterotype_1\", \"0\", \"1\")) %>%\n  mutate(dsestate = if_else(dsestate == \"pHTN\" | dsestate == \"HTN\" , \"0\", \"1\")) %>%\n  select(-dsestate) %>%\n  select(enttype, everything())\n\n\n# Dietswap dataset: Subset for machine learning analysis: Taxonomic genus features with nationality and body mass index group\n\n# Nationality feature\nml_genus_nationality <- ps_df %>%\n  select(sample_id, taxon, nationality, rel_abund, bmi) %>%\n  mutate(\n    taxon = str_replace_all(taxon, \"\\\\*\", \"\"),\n    nationality = factor(if_else(nationality == \"AAM\", \"0\", \"1\"), levels = c(\"0\", \"1\")),\n    bmi = factor(if_else(bmi == \"overweight\" | bmi == \"obese\", \"0\", \"1\"), levels = c(\"0\", \"1\"))\n  ) %>%\n  group_by(sample_id, taxon, nationality, bmi) %>%\n  summarise(rel_abund = mean(rel_abund), .groups = \"drop\") %>%\n  pivot_wider(names_from = taxon, values_from = rel_abund) %>%\n  ungroup() %>%\n  filter(!is.na(nationality)) %>%  # Remove rows with NA in the 'nationality' column\n  select(-c(sample_id, bmi)) %>%\n  mutate(across(starts_with(\"rel_abund\"), as.numeric))\n\n# Body mass index feature\nml_genus_bmi <- ps_df %>%\n  select(sample_id, taxon, nationality, rel_abund, bmi) %>%\n  mutate(\n    taxon = str_replace_all(taxon, \"\\\\*\", \"\"),\n    nationality = factor(if_else(nationality == \"AAM\", \"0\", \"1\"), levels = c(\"0\", \"1\")),\n    bmi = factor(if_else(bmi == \"overweight\" | bmi == \"obese\", \"0\", \"1\"), levels = c(\"0\", \"1\"))\n  ) %>%\n  group_by(sample_id, taxon, nationality, bmi) %>%\n  summarise(rel_abund = mean(rel_abund), .groups = \"drop\") %>%\n  pivot_wider(names_from = taxon, values_from = rel_abund) %>%\n  ungroup() %>%\n  filter(!is.na(bmi)) %>%  # Remove rows with NA in the 'bmi' column\n  select(-c(sample_id, nationality)) %>%\n  mutate(across(starts_with(\"rel_abund\"), as.numeric))\n\n# Save the processed data objects into an RDA file for downstream analysis\nsave(composite,\n     metabo_composite,\n     ml_genus_dsestate,\n     ps_df,\n     ml_genus_enttype, \n     ml_genus_nationality, \n     ml_genus_bmi, \n     file = \"data/ml_n_composite_object.rda\")"},{"path":"feature-engineering-1.html","id":"feature-selection","chapter":"5 Feature Engineering","heading":"5.2 Feature Selection","text":"Objective: Perform feature selection identify relevant microbial taxa functional pathways associated binary outcome interest, disease status treatment response.Techniques: Utilize methods like Lasso regularization, Recursive Feature Elimination (RFE), Boruta algorithm automatically select important features penalize less informative ones, enhancing model interpretability performance.","code":""},{"path":"feature-engineering-1.html","id":"feature-selection-techniques","chapter":"5 Feature Engineering","heading":"5.3 Feature Selection Techniques","text":"Variance Threshold: Identify features low variance, may less informative model, remove consideration.Univariate Selection: Evaluate relationship feature target variable independently, selecting relevant features based statistical tests.Recursive Feature Elimination (RFE): Iteratively remove least significant features model optimal subset features achieved, based model performance metrics.Principal Component Analysis (PCA): Transform original features lower-dimensional space retaining variance, effectively reducing dimensionality data identifying important patterns.Feature Importance: Assess importance feature based contribution model performance, using techniques like Random Forest feature importance permutation importance.","code":""},{"path":"feature-engineering-1.html","id":"variance-threshold","chapter":"5 Feature Engineering","heading":"5.4 Variance threshold","text":"Note: NA values must removed selected_features vector filtering dataset avoid errors.","code":"library(tidyverse)\n\n# Example dataset (replace with your own data)\ndata <- ml_genus_nationality\n# data <- ml_genus_bmi\n# data <- ml_genus_enttype\n# data <- ml_genus_dsestate\n\n# Calculate variance for each feature\nvariances <- apply(data[, -1], 2, var)  # Exclude the first column (nationality)\n\n# Set the threshold for variance\nthreshold <- 0.0001  # Adjust as needed\n\n# Identify features with variance above the threshold\nselected_features <- names(variances[variances > threshold])\n\n# Remove NA values from selected_features\nselected_features <- selected_features[!is.na(selected_features)]\n\n# Add the first column (nationality) to the selected features\nselected_features <- c(\"nationality\", selected_features)\n\n# Filter dataset to include selected features\nfiltered_data <- data[, colnames(data) %in% selected_features]\n\n# Display filtered dataset\nhead(filtered_data[, 1:5])\n# A tibble: 6 × 5\n  nationality Akkermansia Allistipes `Bacteroides fragilis` `Bacteroides ovatus`\n  <fct>             <dbl>      <dbl>                  <dbl>                <dbl>\n1 0              0.00213     0.0397                 0.0524              0.0505  \n2 1              0.00724     0.00180                0.00151             0.000637\n3 1              0.136       0.00897                0.0729              0.00518 \n4 1              0.00101     0.00299                0.00139             0.00112 \n5 1              0.00490     0.00713                0.00312             0.00279 \n6 1              0.000706    0.00116                0.00116             0.000899\n\n\n\nlibrary(dplyr)\nlibrary(caret)\nlibrary(mikropml)\n\ntraining_data <- filtered_data %>%\n  dplyr::rename(target = nationality) %>% \n  mutate(target = recode_factor(target, \"0\" = \"AAM\", \"1\" = \"AFR\"))"},{"path":"data-splitting.html","id":"data-splitting","chapter":"6 Data Splitting","heading":"6 Data Splitting","text":"dataset divided separate subsets training testing. partitioning allows unbiased evaluation model’s performance unseen data, helping assess ability generalize new observations.Using caret::createDataPartition() functionUsing dplyr::sample_n() dplyr::setdiff() functionsVisualize relative abundance selected microbes training testing datasets","code":"set.seed(1234)\n\n# Load necessary libraries\nlibrary(caret)\n\n# Example dataset (replace with your own data)\ndata <- training_data\n\n# Split data into training and testing sets\nset.seed(123) # for reproducibility\ntrain_index <- caret::createDataPartition(data$target, p = 0.8, list = FALSE)\ntrain_data <- data[train_index, ]\ntest_data <- data[-train_index, ]\n\ncat(\"\\nDimension of the test data using caret package\\n is\", base::dim(test_data)[1], \"rows and\", base::dim(test_data)[2], \"columns.\\n\")\n\nDimension of the test data using caret package\n is 43 rows and 27 columns.\ncat(\"\\nDimension of the train data using caret package\\n is\", base::dim(train_data)[1], \"rows and\", base::dim(train_data)[2], \"columns.\\n\")\n\nDimension of the train data using caret package\n is 179 rows and 27 columns.\n\ncat(\"\\nThe intersection between test and train dataset is\", nrow(test_data %>% intersect(train_data)))\n\nThe intersection between test and train dataset is 0set.seed(123)\n\nlibrary(dplyr)\ntest_df = training_data %>% dplyr::sample_n(0.2*nrow(training_data))\ntrain_df = training_data %>% dplyr::setdiff(test_df)\n\ncat(\"\\nDimension of the test data using dplyr package\\n is\", base::dim(test_df)[1], \"rows and\", base::dim(test_df)[2], \"columns.\\n\")\n\nDimension of the test data using dplyr package\n is 44 rows and 27 columns.\ncat(\"\\nDimension of the train data using dplyr package\\n is\", base::dim(train_df)[1], \"rows and\", base::dim(train_df)[2], \"columns.\\n\")\n\nDimension of the train data using dplyr package\n is 178 rows and 27 columns.\n\n\ncat(\"\\nThe intersection between test and train dataset is\", nrow(test_df %>% intersect(train_df)))\n\nThe intersection between test and train dataset is 0\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(ggpubr)\n\ncols <- c(\"AAM\" = \"red\",\"AFR\" = \"green4\")\n\np1 <- train_data %>% ggplot(aes(x = `Bacteroides vulgatus`, y = `Prevotella melaninogenica`, color = factor(target))) + geom_point(size = 2, shape = 16, alpha = 0.6) +\n  labs(title = \"Train Dataset using \\ncaret::createDataPartition() function\") +\n  scale_colour_manual(values = cols, labels = c(\"African American\", \"Africa\"), name=\"Level\") +\n  theme_bw() +\n  theme(text = element_text(size = 8))\n\np2 <- test_data %>% ggplot(aes(x = `Bacteroides vulgatus`, y = `Prevotella melaninogenica`, color = factor(target))) + geom_point(size = 2, shape = 16, alpha = 0.6) +\n  labs(title = \"Test Dataset using \\ncaret::createDataPartition() function\") +\n  scale_colour_manual(values = cols, labels = c(\"African American\", \"Africa\"), name=\"Level\") +\n  theme_bw() +\n  theme(text = element_text(size = 8))\n\n\np3 <- train_df %>% ggplot(aes(x = `Bacteroides vulgatus`, y = `Prevotella melaninogenica`, color = factor(target))) + geom_point(size = 2, shape = 16, alpha = 0.6) +\n  labs(title = \"Train Dataset using dplyr::sample_n() \\nand dplyr::setdiff() functions\") +\n  scale_colour_manual(values = cols, labels = c(\"African American\", \"Africa\"), name=\"Level\") +\n  theme_bw() +\n  theme(text = element_text(size = 8))\n\np4 <- test_df %>% ggplot(aes(x = `Bacteroides vulgatus`, y = `Prevotella melaninogenica`, color = factor(target))) + geom_point(size = 2, shape = 16, alpha = 0.6) +\n  labs(title = \"Test Dataset using dplyr::sample_n() \\nand dplyr::setdiff() functions\") +\n  scale_colour_manual(values = cols, labels = c(\"African American\", \"Africa\"), name=\"Level\") +\n  theme_bw() +\n  theme(text = element_text(size = 8))\n\n# Arrange plots using ggpubr\nggarrange(p1, p2, p3, p4, nrow = 2, ncol = 2, common.legend = TRUE, legend = \"right\", heights = c(1, 1))"},{"path":"model-fitting.html","id":"model-fitting","chapter":"7 Model Fitting","heading":"7 Model Fitting","text":"Microbiome data presents unique challenges opportunities modeling due high dimensionality complexity. section, explore various algorithms suitable modeling microbiome datasets:","code":""},{"path":"model-fitting.html","id":"regularized-logistic-regression","chapter":"7 Model Fitting","heading":"7.1 Regularized Logistic Regression","text":"Regularized Logistic Regression variant logistic regression tailored binary classification tasks commonly encountered microbiome studies. introduces penalty terms Lasso (L1) Ridge (L2) control model complexity prevent overfitting.Regularized Logistic Regression model performance training (using metrics like accuracy)","code":"\nset.seed(1234)\n\nmod_regLogistic_cv <- train(target ~ ., data = training_data,\n                            method = \"regLogistic\",\n                            tuneLength = 12,\n                            trControl = caret::trainControl(method = \"adaptive_cv\",\n                                                             verboseIter = FALSE),\n                            tuneGrid = base::expand.grid(cost = seq(0.001, 1, length.out = 20),\n                                                         loss =  \"L2_primal\",\n                                                         epsilon = 0.01 ))\nset.seed(1234)\n## Visualize the model performance\n\nlibrary(ggplot2)\n\n\n# Plot Accuracy vs. cost for Regularized Logistic Regression Model (Adaptive CV)\nggplot(mod_regLogistic_cv$results, aes(x = cost, y = Accuracy)) +\n  geom_line(color = \"blue\") +\n  geom_point(color = \"black\") +\n  labs(title = \"Accuracy vs. Cost for Regularized Logistic Regression Model (Adaptive CV)\",\n       x = \"Cost\", y = \"Accuracy\") +\n  theme_bw()"},{"path":"model-fitting.html","id":"generalized-linear-models-glmnet","chapter":"7 Model Fitting","heading":"7.2 Generalized Linear Models (glmnet)","text":"glmnet package R fits Generalized Linear Models Lasso Elastic-Net regularization. ’s particularly useful microbiome data analysis due ability handle high-dimensional datasets sparse features.Generalized Linear model performance training (using metrics like accuracy)","code":"\nset.seed(1234)\nmod_glmnet_adcv <- train(target ~ ., data = training_data,\n             method = \"glmnet\",\n             tuneLength = 12,\n             trControl = caret::trainControl(method = \"adaptive_cv\"))\nset.seed(1234)\n## Visualize the model performance\n\nlibrary(ggplot2)\n\n\n# Plot Accuracy vs. lambda for glmnet Model (Adaptive CV)\nggplot(mod_glmnet_adcv$results, aes(x = lambda, y = Accuracy)) +\n  geom_line(color = \"blue\") +\n  geom_point(color = \"black\") +\n  labs(title = \"Accuracy vs. Lambda for glmnet Model (Adaptive CV)\",\n       x = \"Lambda\", y = \"Accuracy\") +\n  theme_bw()"},{"path":"model-fitting.html","id":"random-forest","chapter":"7 Model Fitting","heading":"7.3 Random Forest","text":"Random Forest ensemble learning technique combines multiple decision trees improve predictive performance. ’s well-suited handling high-dimensional nonlinear nature microbiome data mitigating overfitting.Random Forest model performance training (using metrics like accuracy)","code":"\nset.seed(1234)\nmod_rf_reptcv <- train(target ~ ., data = training_data,\n             method = \"rf\",\n             tuneLength = 12,\n             trControl = caret::trainControl(method = \"repeatedcv\"))\n\n\nmod_rf_adcv <- train(target ~ ., data = training_data,\n             method = \"rf\",\n             tuneLength = 12,\n             trControl = caret::trainControl(method = \"adaptive_cv\",\n                      verboseIter = FALSE))\nset.seed(1234)\n## Visualize the model performance\n\nlibrary(ggplot2)\n\n\n# Plot Accuracy vs. mtry for Random Forest Model (Repeated CV)\nggplot(mod_rf_reptcv$results, aes(x = mtry, y = Accuracy)) +\n  geom_line(color = \"blue\") +\n  geom_point(color = \"black\") +\n  labs(title = \"Accuracy vs. mtry for Random Forest Model (Repeated CV)\",\n       x = \"mtry\", y = \"Accuracy\") +\n  theme_bw()\n\n# Plot Accuracy vs. mtry for Random Forest Model (Adaptive CV)\nggplot(mod_rf_adcv$results, aes(x = mtry, y = Accuracy)) +\n  geom_line(color = \"blue\") +\n  geom_point(color = \"black\") +\n  labs(title = \"Accuracy vs. mtry for Random Forest Model (Adaptive CV)\",\n       x = \"mtry\", y = \"Accuracy\") +\n  theme_bw()"},{"path":"model-fitting.html","id":"k-nearest-neighbors-knn","chapter":"7 Model Fitting","heading":"7.4 k-Nearest Neighbors (kNN)","text":"kNN simple yet effective algorithm classification regression tasks microbiome studies. works assigning class label unclassified sample based majority class k nearest neighbors feature space.k-Nearest Neighbors model performance training (using metrics like accuracy)","code":"\nset.seed(1234)\nmod_knn_reptcv <- train(target ~ ., data = training_data,\n                        method = \"knn\",\n                        tuneLength = 12,\n                        trControl = caret::trainControl(method = \"repeatedcv\",\n                                                         repeats = 2))\n\n\nmod_knn_adcv <- train(target ~ ., data = training_data,\n                      method = \"knn\",\n                      tuneLength = 12,\n                      trControl = caret::trainControl(method = \"adaptive_cv\",\n                                                       repeats = 2,\n                                                       verboseIter = FALSE))\nset.seed(1234)\n## Visualize the model performance\n\nlibrary(ggplot2)\n\n# Plot Accuracy vs. k for KNN Model (Repeated CV)\nggplot(mod_knn_reptcv$results, aes(x = k, y = Accuracy)) +\n  geom_line(color = \"blue\") +\n  geom_point(color = \"black\") +\n  labs(title = \"Accuracy vs. k for KNN Model (Repeated CV)\",\n       x = \"k\", y = \"Accuracy\") +\n  theme_bw()\n\n# Plot Accuracy vs. k for KNN Model (Adaptive CV)\nggplot(mod_knn_adcv$results, aes(x = k, y = Accuracy)) +\n  geom_line(color = \"blue\") +\n  geom_point(color = \"black\") +\n  labs(title = \"Accuracy vs. k for KNN Model (Adaptive CV)\",\n       x = \"k\", y = \"Accuracy\") +\n  theme_bw()\nif(!dir.exists(\"models\")) {dir.create(\"models\")}\nsave(mod_glmnet_adcv, mod_regLogistic_cv, mod_rf_adcv, mod_rf_reptcv, mod_knn_adcv, mod_knn_reptcv, file = \"models/models.rda\")"},{"path":"model-fitting.html","id":"decision-trees","chapter":"7 Model Fitting","heading":"7.5 Decision Trees","text":"Decision Trees offer intuitive approach modeling microbiome data recursively partitioning feature space based microbial abundance levels. susceptible overfitting, decision trees provide insights hierarchical structure microbiome communities.","code":""},{"path":"model-fitting.html","id":"support-vector-machines-svm","chapter":"7 Model Fitting","heading":"7.6 Support Vector Machines (SVM)","text":"SVM powerful algorithm classifying microbiome samples based microbial composition. finding optimal hyperplane separates different microbial communities, SVM can effectively discern complex patterns microbiome data.","code":""},{"path":"model-fitting.html","id":"neural-networks","chapter":"7 Model Fitting","heading":"7.7 Neural Networks","text":"Neural Networks, including Deep Learning architectures, offer flexible framework modeling microbiome datasets. models can capture intricate relationships microbial taxa host phenotypes, making valuable tasks disease classification biomarker discovery.","code":""},{"path":"model-fitting.html","id":"gradient-boosting-machines-gbm","chapter":"7 Model Fitting","heading":"7.8 Gradient Boosting Machines (GBM)","text":"GBM ensemble learning method builds sequence decision trees gradually improve predictive accuracy. ’s adept handling complex interactions microbial taxa host factors, making suitable microbiome classification tasks.","code":""},{"path":"model-fitting.html","id":"adaboost","chapter":"7 Model Fitting","heading":"7.9 AdaBoost","text":"AdaBoost boosting algorithm combines multiple weak learners create strong classifier. ’s particularly useful microbiome data classification due ability focus difficult--classify samples improve overall model performance.","code":""},{"path":"model-fitting.html","id":"naive-bayes","chapter":"7 Model Fitting","heading":"7.10 Naive Bayes","text":"Naive Bayes probabilistic classifier based Bayes’ theorem assumption independence features. simplicity makes computationally efficient, Naive Bayes can still provide competitive performance microbiome classification tasks.\ncertain models utilize lambda, Regularized Logistic\nRegression models, capability set lambda using\nexpressions define sequence numerical values. instance,\nemploying expression 10^seq(-3, 3, = 0.5) results \ngeneration numbers raising 10 power element\nwithin sequence ranging -3 3, increment 0.5. \noutput presents sequence values, 10^-3, 10^-2.5, 10^-2,\n10^-1.5, 10^-1, 10^-0.5, 10^0, 10^0.5, 10^1, 10^1.5, 10^2, 10^2.5, \n10^3.\n","code":""},{"path":"model-fitting.html","id":"cross-validation-techniques","chapter":"7 Model Fitting","heading":"7.11 Cross-Validation Techniques","text":"Cross-validation method used evaluate performance generalization ability predictive models. involves partitioning available data multiple subsets, known folds. model trained portion data (training set) evaluated remaining data (validation set). process repeated multiple times, fold serving validation set exactly . Cross-validation provides robust estimate model’s performance compared single train-test split helps identify overfitting.section, explore various cross-validation techniques. Understanding methods essential play significant role subsequent hyperparameter tuning. Cross-validation ensures robust model evaluation assists selecting optimal hyperparameters improved model performance.","code":""},{"path":"model-fitting.html","id":"k-fold-cross-validation","chapter":"7 Model Fitting","heading":"7.12 K-Fold Cross-Validation","text":"K-Fold Cross-Validation divides data K equal-sized folds. model trained K times, time using K-1 folds training set remaining fold validation set.","code":"\n# Example of K-Fold Cross-Validation\nkfcv_ctrl <- caret::trainControl(method = \"cv\", number = 10)"},{"path":"model-fitting.html","id":"leave-one-out-cross-validation-loocv","chapter":"7 Model Fitting","heading":"7.13 Leave-One-Out Cross-Validation (LOOCV)","text":"Leave-One-Cross-Validation involves using single observation validation set remaining observations training set. process repeated observation dataset.","code":"\n# Example of Leave-One-Out Cross-Validation\nloocv_ctrl <- caret::trainControl(method = \"LOOCV\")"},{"path":"model-fitting.html","id":"stratified-cross-validation","chapter":"7 Model Fitting","heading":"7.14 Stratified Cross-Validation","text":"Stratified Cross-Validation ensures fold maintains class distribution original dataset. particularly useful imbalanced datasets.","code":"\n# Example of Stratified Cross-Validation\nstrcv_ctrl <- trainControl(method = \"cv\", \n                     number = 10, \n                     classProbs = TRUE, \n                     summaryFunction = twoClassSummary)"},{"path":"model-fitting.html","id":"nested-cross-validation","chapter":"7 Model Fitting","heading":"7.15 Nested Cross-Validation","text":"Nested Cross-Validation used tune hyperparameters evaluate model performance simultaneously. involves outer loop model evaluation using K-Fold Cross-Validation inner loop hyperparameter tuning.","code":"\n# Example of Nested Cross-Validation\nnestcv_ctrl_outer <- trainControl(method = \"cv\", number = 5)\nnetscv_ctrl_inner <- trainControl(method = \"cv\", number = 3)"},{"path":"hyperparameter-tuning.html","id":"hyperparameter-tuning","chapter":"8 Hyperparameter Tuning","heading":"8 Hyperparameter Tuning","text":"stage, objective refine parameters utilized model fitting maximize performance. concentrate optimizing model’s effectiveness fine-tuning various hyperparameters. parameters, regularization strength tree depth, manually adjusted enhance model’s accuracy. experimentation different values, goal pinpoint optimal combination maximizes performance validation data. pivotal step ensures model excels training data also generalizes effectively new, unseen data.","code":""},{"path":"hyperparameter-tuning.html","id":"demo-tuning-for-a-rlr-model","chapter":"8 Hyperparameter Tuning","heading":"8.1 Demo tuning for a RLR Model","text":"","code":"\n# Set seed for reproducibility\nset.seed(110912)\n\n# Load necessary libraries\nlibrary(caret)\nlibrary(ggplot2)\n\n# Define the tuning grid\ntuneGrid <- expand.grid(\n  cost = seq(0.001, 1, length.out = 20),  # Define a sequence of cost values\n  loss = \"L2_primal\",  # Specify the loss function\n  epsilon = 0.01  # Set the epsilon value\n)\n\n# Set up cross-validation method\nctrl <- trainControl(\n  method = \"adaptive_cv\",  # Use adaptive cross-validation\n  verboseIter = FALSE  # Print progress during each iteration\n)\n\n# Perform hyperparameter tuning\nmod_regLogistic_cv <- train(\n  target ~ .,  # Define the formula for the model\n  data = training_data,  # Specify the training dataset\n  method = \"regLogistic\",  # Choose the regularized logistic regression method\n  tuneLength = 12,  # Set the number of tuning parameter combinations to try\n  trControl = ctrl,  # Specify the cross-validation method\n  tuneGrid = tuneGrid  # Use the defined tuning grid\n)\n\n# Visualize the model performance\nggplot(mod_regLogistic_cv$results, aes(x = cost, y = Accuracy)) +\n  geom_line(color = \"blue\") +  # Add a line plot\n  geom_point(color = \"black\") +  # Add points for each data point\n  labs(\n    title = \"Accuracy vs. Cost for Regularized Logistic Regression Model (Adaptive CV)\",  # Set the plot title\n    x = \"Cost\",  # Label the x-axis\n    y = \"Accuracy\"  # Label the y-axis\n  ) +\n  theme_bw()  # Apply a black and white theme"},{"path":"computing-confusion-matrix.html","id":"computing-confusion-matrix","chapter":"9 Computing Confusion Matrix","heading":"9 Computing Confusion Matrix","text":"Confusion Matrix summarizes performance classification model tabulating true positive, true negative, false positive, false negative predictions.","code":"# Load necessary libraries\nlibrary(caret)\n# Predict using the trained model\npredictions <- predict(mod_regLogistic_cv, newdata = test_data)\n\n# Compute confusion matrix\nconfusion_matrix <- caret::confusionMatrix(predictions, test_data$target)\n\nprint(confusion_matrix)\nConfusion Matrix and Statistics\n\n          Reference\nPrediction AAM AFR\n       AAM  19   3\n       AFR   5  16\n                                         \n               Accuracy : 0.814          \n                 95% CI : (0.666, 0.9161)\n    No Information Rate : 0.5581         \n    P-Value [Acc > NIR] : 0.000393       \n                                         \n                  Kappa : 0.6269         \n                                         \n Mcnemar's Test P-Value : 0.723674       \n                                         \n            Sensitivity : 0.7917         \n            Specificity : 0.8421         \n         Pos Pred Value : 0.8636         \n         Neg Pred Value : 0.7619         \n             Prevalence : 0.5581         \n         Detection Rate : 0.4419         \n   Detection Prevalence : 0.5116         \n      Balanced Accuracy : 0.8169         \n                                         \n       'Positive' Class : AAM            \n                                         "},{"path":"computing-confusion-matrix.html","id":"accuracy","chapter":"9 Computing Confusion Matrix","heading":"9.1 Accuracy","text":"Accuracy measures proportion correctly classified instances total number instances. intuitive, accuracy may suitable imbalanced datasets, majority class dominates classification.","code":"\nlibrary(caret)\naccuracy <- confusion_matrix$overall[\"Accuracy\"]\naccuracy\n Accuracy \n0.8139535 "},{"path":"computing-confusion-matrix.html","id":"precision-and-recall","chapter":"9 Computing Confusion Matrix","heading":"9.2 Precision and Recall","text":"Precision measures proportion correctly predicted positive instances instances predicted positive. Recall, also known sensitivity, measures proportion correctly predicted positive instances actual positive instances.","code":"\nlibrary(caret)\nprecision <- confusion_matrix$byClass[\"Precision\"]\nprecision\nPrecision \n0.8636364 \nrecall <- confusion_matrix$byClass[\"Recall\"]\nrecall\n   Recall \n0.7916667 "},{"path":"computing-confusion-matrix.html","id":"f1-score","chapter":"9 Computing Confusion Matrix","heading":"9.3 F1 Score","text":"F1 Score harmonic mean precision recall. provides balanced assessment classifier’s performance, considering false positives false negatives.","code":"\nlibrary(caret)\nf1 <- confusion_matrix$byClass[\"F1\"]\nf1\n      F1 \n0.826087 "},{"path":"computing-confusion-matrix.html","id":"performance-metrics-dataframe","chapter":"9 Computing Confusion Matrix","heading":"9.4 Performance metrics dataframe","text":"","code":"# Create a data frame for model performance metrics\nperformance_metrics <- data.frame(\n  Metric = c(\"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"),\n  Value = c(accuracy, precision, recall, f1)\n)\n\nperformance_metrics\n             Metric     Value\nAccuracy   Accuracy 0.8139535\nPrecision Precision 0.8636364\nRecall       Recall 0.7916667\nF1         F1 Score 0.8260870"},{"path":"computing-confusion-matrix.html","id":"visualize-model-performance-metrics","chapter":"9 Computing Confusion Matrix","heading":"9.5 Visualize model performance metrics","text":"","code":"\nggplot(performance_metrics, aes(x = Metric, y = Value)) +\n  geom_bar(stat = \"identity\", fill = \"steelblue\", color = \"black\") +\n  labs(x = \"Metric\", y = \"Value\", title = \"Model Performance Metrics\") +\n  theme_minimal()"},{"path":"computing-confusion-matrix.html","id":"roc-curve-and-auc-roc","chapter":"9 Computing Confusion Matrix","heading":"9.6 ROC Curve and AUC-ROC","text":"ROC Curve plots true positive rate (sensitivity) false positive rate (1 - specificity) various threshold settings. provides visual representation classifier’s performance across different threshold levels. Area ROC Curve (AUC-ROC) quantifies overall performance model distinguishing positive negative classes. higher AUC-ROC value indicates better discrimination performance.","code":"\nlibrary(pROC)\nlibrary(ggplot2)\n\n# Compute predicted probabilities\npredicted_probabilities <- predict(mod_regLogistic_cv, newdata = test_data, type = \"prob\")\n\n# Extract probabilities for the positive class\npositive_probabilities <- predicted_probabilities$AAM\n\n# Compute ROC curve and AUC-ROC\nroc_curve <- pROC::roc(test_data$target, positive_probabilities)\nauc_roc <- pROC::auc(roc_curve)\n\n# Plot ROC curve with descriptive axis titles\nggroc(roc_curve, color = \"steelblue\", size = 1) +\n  labs(title = \"Receiver Operating Characteristic (ROC) Curve\",\n       x = \"False Positive Rate (1 - Specificity)\",\n       y = \"True Positive Rate (Sensitivity)\") +\n  theme_minimal()\n\n\n# Print AUC-ROC\ncat(\"AUC-ROC:\", auc_roc)\nAUC-ROC: 0.8552632"},{"path":"computing-confusion-matrix.html","id":"significant-genera-with-wilcox.test","chapter":"9 Computing Confusion Matrix","heading":"9.7 Significant genera with wilcox.test","text":"Wilcoxon rank sum test, also known Mann-Whitney U test, nonparametric test used assess whether two independent samples different distributions. particularly useful assumptions t-test met, data normally distributed sample sizes small","code":"\nlibrary(purrr)\nlibrary(dplyr)\nlibrary(tidyr)\n\nall_genera <- composite %>%\n  tidyr::nest(data = -taxonomy) %>%\n  mutate(test = purrr::map(.x=data, ~wilcox.test(rel_abund~hyper, data=.x) %>% tidy)) %>%\n  tidyr::unnest(test) %>%\n  mutate(p.adjust = p.adjust(p.value, method=\"BH\"))\n\nsig_genera <- all_genera %>% \n  dplyr::filter(p.value < 0.001) %>%\n  arrange(p.adjust) %>% \n  dplyr::select(taxonomy, p.value)"},{"path":"computing-confusion-matrix.html","id":"view-distribution-of-significant-genera","chapter":"9 Computing Confusion Matrix","heading":"9.8 View distribution of significant genera","text":"","code":"\ncomposite %>%\n  inner_join(sig_genera, by=\"taxonomy\") %>%\n  mutate(rel_abund = 100 * (rel_abund + 1/20000),\n         taxonomy = str_replace(taxonomy, \"(.*)\", \"*\\\\1*\"),\n         taxonomy = str_replace(taxonomy, \"\\\\*(.*)_unclassified\\\\*\",\n                                \"Unclassified<br>*\\\\1*\"),\n         hyper = factor(hyper, levels = c(T, F))) %>%\n  ggplot(aes(x=rel_abund, y=taxonomy, color=hyper, fill=hyper)) +\n  # geom_vline(xintercept = 100/10530, size=0.5, color=\"gray\") +\n  geom_jitter(position = position_jitterdodge(dodge.width = 0.8,\n                                              jitter.width = 0.5),\n              shape=21) +\n  stat_summary(fun.data = median_hilow, fun.args = list(conf.int=0.5),\n               geom=\"pointrange\",\n               position = position_dodge(width=0.8),\n               color=\"black\", show.legend = FALSE) +\n  scale_x_log10() +\n  scale_color_manual(NULL,\n                     breaks = c(F, T),\n                     values = c(\"gray\", \"dodgerblue\"),\n                     labels = c(\"Control\", \"Hypertension\")) +\n  scale_fill_manual(NULL,\n                     breaks = c(F, T),\n                     values = c(\"gray\", \"dodgerblue\"),\n                     labels = c(\"Control\", \"Hypertension\")) +\n  labs(x= \"Relative abundance (%)\", y=NULL) +\n  theme_classic() +\n  theme(\n    axis.text.y = element_markdown()\n  )\n\nggsave(\"figures/significant_genera.tiff\", width=6, height=4)"},{"path":"computing-confusion-matrix.html","id":"significant-pathways","chapter":"9 Computing Confusion Matrix","heading":"9.9 Significant pathways","text":"Compute significant pathways using wilcox.test.","code":"\nlibrary(tidyverse)\n\nall_metabopwy <- metabo_composite %>%\n  tidyr::nest(data = -metabopwy) %>%\n  mutate(test = purrr::map(.x=data, ~wilcox.test(rel_abund~hyper, data=.x) %>% tidy)) %>%\n  tidyr::unnest(test) %>%\n  mutate(p.adjust = p.adjust(p.value, method=\"BH\"))\n\nsig_metabopwy <- all_metabopwy %>% \n  dplyr::filter(p.value < 0.3) %>% # Typically, the best significant p-value is set at 0.05\n  dplyr::select(metabopwy, p.value)"},{"path":"computing-confusion-matrix.html","id":"view-distribution-of-significant-metabolic-pathways","chapter":"9 Computing Confusion Matrix","heading":"9.10 View distribution of significant metabolic pathways","text":"Compute significant pathways, thenP-values Adjusted P-values (p.adjust) can used measure significance levels.View distribution significant pathways.filter metabolic pathways lesser stringent p.values (p < 0.25) demo purposes.","code":"\nmetabo_composite %>%\n  inner_join(sig_metabopwy, by=\"metabopwy\") %>%\n  mutate(rel_abund = 100 * (rel_abund + 1/20000),\n         metabopwy = str_replace(metabopwy, \"(.*)\", \"*\\\\1*\"),\n         metabopwy = str_replace(metabopwy, \"\\\\*(.*)_unclassified\\\\*\",\n                                \"Unclassified<br>*\\\\1*\"),\n         hyper = factor(hyper, levels = c(T, F))) %>%\n  ggplot(aes(x=rel_abund, y=metabopwy, color=hyper, fill=hyper)) +\n  geom_jitter(position = position_jitterdodge(dodge.width = 0.8,\n                                              jitter.width = 0.5),\n              shape=21) +\n  stat_summary(fun.data = median_hilow, fun.args = list(conf.int=0.5),\n               geom=\"pointrange\",\n               position = position_dodge(width=0.8),\n               color=\"black\", show.legend = FALSE) +\n  scale_x_log10() +\n  scale_color_manual(NULL,\n                     breaks = c(F, T),\n                     values = c(\"gray\", \"dodgerblue\"),\n                     labels = c(\"Control\", \"Hypertension\")) +\n  scale_fill_manual(NULL,\n                     breaks = c(F, T),\n                     values = c(\"gray\", \"dodgerblue\"),\n                     labels = c(\"Control\", \"Hypertension\")) +\n  labs(x= \"Relative abundance (%)\", y=NULL) +\n  theme_classic() +\n  theme(\n    axis.text.y = element_markdown()\n  )\n\nggsave(\"figures/significant_genera.tiff\", width=6, height=4)"},{"path":"model-deployment.html","id":"model-deployment","chapter":"10 Model Deployment","heading":"10 Model Deployment","text":"Deploying trained model regularized logistic regression model others essential predicting binary outcomes microbiome studies. Additionally, implementing monitoring mechanisms crucial track model performance time detect deviations anomalies. ensures continued reliability accuracy microbiome data analysis.Shiny applications serve interfaces machine learning models, providing users convenient platform upload data test model’s performance efficiently.","code":""},{"path":"model-deployment.html","id":"data-processing","chapter":"10 Model Deployment","heading":"10.1 Data Processing","text":"Conduct various tests ensure functionality system.Collect results tests, may involve multiple types assessments.Determine whether test accepted rejected based collected data.Save developed model future use.","code":""},{"path":"model-deployment.html","id":"application-process","chapter":"10 Model Deployment","heading":"10.2 Application Process","text":"Develop regularized logistic regression model tailored task.Create Shiny application incorporating developed model.Enable users upload test data directly Shiny app.Visualize download predictions generated model Shiny interface.","code":""},{"path":"model-deployment.html","id":"creating-shiny-app","chapter":"10 Model Deployment","heading":"10.3 Creating Shiny App","text":"","code":""},{"path":"model-deployment.html","id":"load-trained-model","chapter":"10 Model Deployment","heading":"10.3.1 Load trained model","text":"","code":"load(\"models/models.rda\", verbose = TRUE)\nLoading objects:\n  mod_glmnet_adcv\n  mod_regLogistic_cv\n  mod_rf_adcv\n  mod_rf_reptcv\n  mod_knn_adcv\n  mod_knn_reptcv"},{"path":"model-deployment.html","id":"create-user-interfale-object","chapter":"10 Model Deployment","heading":"10.3.2 Create user interfale object","text":"user interface object controls layout appearance app.","code":""},{"path":"model-deployment.html","id":"example-app-with-qualitative-data-using-burro-package","chapter":"10 Model Deployment","heading":"10.4 Example APP with Qualitative data using Burro package","text":"\nlibrary(burro)\n\nlibrary(NHANES)\n\ndata(NHANES)\n\nNHANES %>% mutate(gr = 1) %>% ggplot(aes_string(x =\n“AgeDecade”, fill = “AgeDecade”)) + geom_bar(aes(y = ..count..), color =\n“black”) + viridis::scale_fill_viridis(discrete = TRUE, option =\n“magma”) + geom_text(aes(group = gr, label = scales::percent(..prop..),\ny = ..count..), stat = “count”, vjust = -0.5) + theme(axis.text.x =\nelement_text(angle = 90), legend.position = “none”)\n\ndata_dict <-\nreadr::read_csv(system.file(“nhanes/data_dictionary.csv”,\npackage=“burro”))\n\noutcome <- c(“Depressed”)\n\nexplore_data(dataset=NHANES, data_dictionary=data_dict,\noutcome_var=outcome)\n","code":""},{"path":"modeling-ideas.html","id":"modeling-ideas","chapter":"A Modeling Ideas","heading":"A Modeling Ideas","text":"case study, explore performance predictive model developed assess likelihood cancer patients based various medical records. model incorporated patient demographics, medical history, vital signs, diagnostic test results. tested held-dataset, demonstrated exceptional accuracy evaluation.However, upon deployment predict cancer likelihood new patients, model exhibited significant discrepancies performance. discrepancy led investigation uncover potential causes observed inconsistency.","code":""},{"path":"modeling-ideas.html","id":"identifying-the-issue","chapter":"A Modeling Ideas","heading":"A.1 Identifying the Issue","text":"Upon closer examination, became evident model’s poor performance new patients attributed information leakage. Specifically, one feature model inadvertently exposed sensitive information, influenced predictions. form information leakage compromised model’s ability generalize unseen data effectively.","code":""},{"path":"modeling-ideas.html","id":"implications","chapter":"A Modeling Ideas","heading":"A.2 Implications","text":"Information leakage poses serious implications predictive model’s reliability fairness. inadvertently incorporating sensitive information, patient-specific details external factors related prediction task, model’s performance new data can compromised. can lead inaccurate predictions potentially harmful outcomes relied upon clinical decision-making.","code":""},{"path":"modeling-ideas.html","id":"recommendations","chapter":"A Modeling Ideas","heading":"A.3 Recommendations","text":"Conducting thorough feature selection validation processes imperative address information leakage ensure model’s robustness generalizability. involves identifying removing features may inadvertently expose sensitive information introduce bias model. Additionally, implementing rigorous data preprocessing techniques adhering best practices model development can help mitigate risk information leakage enhance reliability predictive models.prioritizing transparency, fairness, ethical considerations throughout model development process, can mitigate risks associated information leakage build accurate trustworthy predictive models.","code":""},{"path":"modeling-ideas.html","id":"some-effective-ml-guidelines","chapter":"A Modeling Ideas","heading":"A.4 Some Effective ML Guidelines","text":"Keep first model simple.Focus ensuring data pipeline correctness.Use simple, observable metric training & evaluation.monitor input featuresTreat model configuration code: review , check inWrite results experiments, especially “failures”","code":""},{"path":"using-ml-helper-function.html","id":"using-ml-helper-function","chapter":"B Using ML helper function","heading":"B Using ML helper function","text":"know different hyperparameter options dafault values different modeling approaches","code":"load(\"data/ml_n_composite_object.rda\", verbose = TRUE)\nLoading objects:\n  composite\n  metabo_composite\n  ml_genus_dsestate\n  ps_df\n  ml_genus_enttype\n  ml_genus_nationality\n  ml_genus_bmilibrary(mikropml)\n\nget_hyperparams_list(ml_genus_nationality, \"glmnet\")\n$lambda\n[1] 1e-04 1e-03 1e-02 1e-01 1e+00 1e+01\n\n$alpha\n[1] 0\nget_hyperparams_list(ml_genus_nationality, \"rf\")\n$mtry\n[1]  6 12 24\nget_hyperparams_list(ml_genus_nationality, \"svmRadial\")\n$C\n[1] 1e-03 1e-02 1e-01 1e+00 1e+01 1e+02\n\n$sigma\n[1] 1e-06 1e-05 1e-04 1e-03 1e-02 1e-01\nget_hyperparams_list(ml_genus_nationality, \"rpart2\") # Decision tree\n$maxdepth\n[1]  1  2  4  8 16 30\nget_hyperparams_list(ml_genus_nationality, \"xgbTree\") # XGBoost\n$nrounds\n[1] 100\n\n$gamma\n[1] 0\n\n$eta\n[1] 0.001 0.010 0.100 1.000\n\n$max_depth\n[1]  1  2  4  8 16 30\n\n$colsample_bytree\n[1] 0.8\n\n$min_child_weight\n[1] 1\n\n$subsample\n[1] 0.4 0.5 0.6 0.7"},{"path":"imap-github-repos.html","id":"imap-github-repos","chapter":"C IMAP GitHub Repos","heading":"C IMAP GitHub Repos","text":"","code":""},{"path":"session-information.html","id":"session-information","chapter":"D Session Information","heading":"D Session Information","text":"Reproducibility relies ability precisely recreate working environment, session information serves vital reference achieve consistency. record details R environment, package versions, system settings computing environment time analysis.","code":"\nlibrary(sessioninfo)\n\n# Get session info\ninfo <- capture.output(print(session_info()))\n\n# Define patterns to exclude\nexclude_patterns <- c(\"/Users/.*\", \"Africa/Dar_es_Salaam\") # This line is location-dependent\n\n# Exclude lines containing specific information\ninfo_filtered <- info[!grepl(paste(exclude_patterns, collapse = \"|\"), info)]\n\n# Save the filtered session info to a text file in the root directory without line numbers\ncat(info_filtered, file = \"session_info.txt\", sep = \"\\n\")"},{"path":"references.html","id":"references","chapter":"References","heading":"References","text":"","code":""}]
